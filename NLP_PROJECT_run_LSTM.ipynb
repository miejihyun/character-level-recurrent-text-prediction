{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1e_jsiIyvPON"
      },
      "source": [
        "# **IMPORTS & UTILS**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive \n",
        "import os\n",
        "drive.mount('/content/drive')\n",
        "path = \"/content/drive/MyDrive/NLP_PROJECT/\"\n",
        "\n",
        "if not os.path.exists(path):\n",
        "    os.mkdir(path)\n",
        "\n",
        "if not os.path.exists(path+\"/cache/\"):\n",
        "    os.mkdir(path+\"/cache/\")\n",
        "\n",
        "os.chdir(path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "677x_gECuDGR",
        "outputId": "0cdbbfa2-5887-4889-ce3f-d4e7d1e54a67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7YcPJfCVvAUn"
      },
      "outputs": [],
      "source": [
        "import nltk, math, torch\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import namedtuple\n",
        "from nltk.corpus import brown\n",
        "import numpy as np\n",
        "\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "from utils import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AShS4PYrvTII"
      },
      "source": [
        "## **Corpus Initializations**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBEMxhwVvLzv"
      },
      "outputs": [],
      "source": [
        "def init_brown():\n",
        "    nltk.download('brown')\n",
        "    words = brown.words(categories=(brown.categories()))\n",
        "    N     = len(words)\n",
        "\n",
        "    words_test  = words[0:math.ceil(N*0.7)]\n",
        "    words_train = words[math.ceil(N*0.7):math.ceil(N*0.9)]\n",
        "    words_val   = words[math.ceil(N*0.9):]\n",
        "\n",
        "    f=open('test.txt','w')\n",
        "    for w in words_test:\n",
        "        f.write(w+\" \")\n",
        "    f.close()\n",
        "\n",
        "    f=open('train.txt','w')\n",
        "    for w in words_train:\n",
        "        f.write(w+\" \")\n",
        "    f.close()\n",
        "\n",
        "    f=open('valid.txt','w')\n",
        "    for w in words_val:\n",
        "        f.write(w+\" \")\n",
        "    f.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preprocess"
      ],
      "metadata": {
        "id": "AHMTC0iKzneX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_char = 0\n",
        "def preprocess(): \n",
        "    global num_char\n",
        "    word_dict, char_dict = create_word_char_dict(\"valid.txt\", \"train.txt\", \"test.txt\")\n",
        "    num_words = len(word_dict)\n",
        "    num_char  = len(char_dict)\n",
        "    char_dict[\"BOW\"] = num_char+1\n",
        "    char_dict[\"EOW\"] = num_char+2\n",
        "    char_dict[\"PAD\"] = 0\n",
        "    \n",
        "    #  dict of (int, string)\n",
        "    reverse_word_dict = {value:key for key, value in word_dict.items()}\n",
        "    max_word_len = max([len(word) for word in word_dict])\n",
        "\n",
        "    objects = {\n",
        "        \"word_dict\": word_dict,\n",
        "        \"char_dict\": char_dict,\n",
        "        \"reverse_word_dict\": reverse_word_dict,\n",
        "        \"max_word_len\": max_word_len\n",
        "    }\n",
        "    \n",
        "    torch.save(objects, \"cache/prep_\"+corpus+\".pt\")\n",
        "    print(\"Preprocess done.\")"
      ],
      "metadata": {
        "id": "a1oBIR1ZzpPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset prep"
      ],
      "metadata": {
        "id": "uxp_Gsc6zlBO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dataset_prep():\n",
        "    train_text = read_data(\"train.txt\")\n",
        "    valid_text = read_data(\"valid.txt\")\n",
        "    test_text  = read_data(\"test.txt\")\n",
        "\n",
        "    train_set = np.array(text2vec(train_text, char_dict, max_word_len))\n",
        "    valid_set = np.array(text2vec(valid_text, char_dict, max_word_len))\n",
        "    test_set  = np.array(text2vec(test_text,  char_dict, max_word_len))\n",
        "\n",
        "    # Labels are next-word index in word_dict with the same length as inputs\n",
        "    train_label = np.array([word_dict[w] for w in train_text[1:]] + [word_dict[train_text[-1]]])\n",
        "    valid_label = np.array([word_dict[w] for w in valid_text[1:]] + [word_dict[valid_text[-1]]])\n",
        "    test_label  = np.array([word_dict[w] for w in test_text[1:]] + [word_dict[test_text[-1]]])\n",
        "\n",
        "    category = {\"tdata\":train_set, \"vdata\":valid_set, \"test\": test_set, \n",
        "                \"trlabel\":train_label, \"vlabel\":valid_label, \"tlabel\":test_label}\n",
        "    torch.save(category, \"cache/data_sets_\"+corpus+\".pt\") "
      ],
      "metadata": {
        "id": "SjHkdrZCzkp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training loop"
      ],
      "metadata": {
        "id": "6aUeQz-64s7j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTM"
      ],
      "metadata": {
        "id": "zCO3Rn6pswTS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_LSTM(net, data, opt, model_name):\n",
        "    global results\n",
        "    torch.manual_seed(1024)\n",
        "\n",
        "    train_input = torch.from_numpy(data.train_input)\n",
        "    train_label = torch.from_numpy(data.train_label)\n",
        "    valid_input = torch.from_numpy(data.valid_input)\n",
        "    valid_label = torch.from_numpy(data.valid_label)\n",
        "\n",
        "    L = opt.seq_len\n",
        "\n",
        "    # [num_seq, seq_len, max_word_len+2]\n",
        "    num_seq = train_input.size()[0] //  L\n",
        "    train_input = train_input[:num_seq* L, :]\n",
        "    train_input = train_input.view(-1,  L, opt.max_word_len+2)\n",
        "\n",
        "    num_seq = valid_input.size()[0] //  L\n",
        "    valid_input = valid_input[:num_seq* L, :]\n",
        "    valid_input = valid_input.view(-1,  L, opt.max_word_len+2)\n",
        "\n",
        "    num_epoch = opt.epochs\n",
        "    num_iter_train = train_input.size()[0] // opt.batch_size\n",
        "    \n",
        "    learning_rate = opt.init_lr\n",
        "    old_PPL = 100000\n",
        "    best_PPL = 100000\n",
        "\n",
        "    n_stuck = 0\n",
        "\n",
        "    # Log-SoftMax\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    \n",
        "    # word_emb_dim == hidden_size / num of hidden units \n",
        "    hidden = (to_var(torch.zeros(2,  opt.batch_size, opt.word_embed_dim)), \n",
        "              to_var(torch.zeros(2,  opt.batch_size, opt.word_embed_dim)))\n",
        "\n",
        "    for epoch in range(num_epoch):\n",
        "        ################  Validation  ####################\n",
        "        net.eval()\n",
        "        loss_batch = []\n",
        "        PPL_batch  = []\n",
        "        num_iter_valid = valid_input.size()[0] // opt.batch_size\n",
        "\n",
        "\n",
        "        # TRANSFORMER :\n",
        "        # VALID  : S+L sequences\n",
        "        # LABELS : S+L labels of next words -> use the (-L,1) labels\n",
        "        \n",
        "        valid_generator  = batch_generator(valid_input, opt.batch_size)\n",
        "        vlabel_generator = batch_generator(valid_label, opt.batch_size*L)\n",
        "\n",
        "        for t in range(num_iter_valid):\n",
        "            batch_input = valid_generator.__next__()  # (N,L,W)\n",
        "            batch_label = vlabel_generator.__next__() # (N*L)\n",
        "\n",
        "            ####################################################################\n",
        "\n",
        "            hidden = [state.detach() for state in hidden]\n",
        "            valid_output, hidden = net(to_var(batch_input), hidden)\n",
        "            ####################################################################\n",
        "\n",
        "            length = valid_output.size()[0]\n",
        "\n",
        "            # [num_sample-1, len(word_dict)] vs [num_sample-1]\n",
        "\n",
        "            valid_loss = criterion(valid_output, to_var(batch_label))\n",
        "\n",
        "            PPL = torch.exp(valid_loss.data)\n",
        "\n",
        "            loss_batch.append(float(valid_loss))\n",
        "            PPL_batch.append(float(PPL))\n",
        "\n",
        "        PPL = np.mean(PPL_batch)\n",
        "        print(\"[epoch {}] valid PPL={}\".format(epoch, PPL))\n",
        "        print(\"valid loss={}\".format(np.mean(loss_batch)))\n",
        "        print(\"PPL decrease={}\".format(float(old_PPL - PPL)))\n",
        "\n",
        "        # UPDATE RESULTS DICT\n",
        "        if results.get(model_name) == None:\n",
        "            results[model_name] = {\"validation\":{\"loss\":[],\"PPL\":[]},\"training\":{\"loss\":[],\"PPL\":[]}}\n",
        "        results[model_name][\"validation\"][\"loss\"].append(np.mean(loss_batch))\n",
        "        results[model_name][\"validation\"][\"PPL\"].append(PPL)\n",
        "\n",
        "        # Preserve the best model\n",
        "        if best_PPL > PPL:\n",
        "            best_PPL = PPL\n",
        "            torch.save(net.state_dict(), \"cache/\"+model_name+\".pt\")\n",
        "            torch.save(net, \"cache/\"+model_name+\"_net.pkl\")\n",
        "\n",
        "        # Adjust the learning rate\n",
        "        if float(old_PPL - PPL) <= 1.0 and n_stuck > 5:\n",
        "            learning_rate /= 10\n",
        "            print(\"halved lr:{}\".format(learning_rate))\n",
        "            n_stuck = 0\n",
        "        elif float(old_PPL - PPL) <= 1.0:\n",
        "            n_stuck += 1\n",
        "\n",
        "        old_PPL = PPL\n",
        "\n",
        "        ##################################################\n",
        "        #################### Training ####################\n",
        "        net.train()\n",
        "\n",
        "        optimizer  = optim.Adam(net.parameters(), \n",
        "                               lr = learning_rate)\n",
        "\n",
        "        # split the first dim\n",
        "        input_generator = batch_generator(train_input, opt.batch_size)\n",
        "        label_generator = batch_generator(train_label, opt.batch_size*L)\n",
        "\n",
        "        total_loss, total_PPL = 0, 0\n",
        "\n",
        "        for t in range(num_iter_train):\n",
        "\n",
        "            if t % 100 == 0:\n",
        "                print(f\"{t}/{num_iter_train}\")\n",
        "\n",
        "            batch_input = input_generator.__next__()\n",
        "            batch_label = label_generator.__next__()\n",
        "            ####################################################################\n",
        "\n",
        "            # detach hidden state of LSTM from last batch\n",
        "            hidden = [state.detach() for state in hidden]\n",
        "            \n",
        "            ####################################################################\n",
        "\n",
        "            output, hidden = net(to_var(batch_input), hidden)\n",
        "            # [num_word, vocab_size]\n",
        "            ####################################################################\n",
        "            loss = criterion(output, to_var(batch_label))\n",
        "\n",
        "            net.zero_grad()\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm(net.parameters(), 5, norm_type=2)\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.cpu().data\n",
        "            total_PPL  += np.exp(loss.cpu().data)\n",
        "          \n",
        "        total_loss /= num_iter_train \n",
        "        total_PPL  /= num_iter_train \n",
        "    \n",
        "        results[model_name][\"training\"][\"loss\"].append(total_loss)\n",
        "        results[model_name][\"training\"][\"PPL\"].append(total_PPL)\n",
        "\n",
        "        print(f\"Train loss : {total_loss}\")\n",
        "        print(f\"Train PPL : {total_PPL}\")\n",
        "\n",
        "    torch.save(net.state_dict(), \"cache/\"+model_name+\".pt\")\n",
        "    print(\"Training finished.\")"
      ],
      "metadata": {
        "id": "pViF2ID-4uty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transformer"
      ],
      "metadata": {
        "id": "w8TXNce6v6zE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_Transformer(net, data, opt, model_name):\n",
        "    global results\n",
        "    torch.manual_seed(1024)\n",
        "\n",
        "    train_input = torch.from_numpy(data.train_input)\n",
        "    train_label = torch.from_numpy(data.train_label)\n",
        "    valid_input = torch.from_numpy(data.valid_input)\n",
        "    valid_label = torch.from_numpy(data.valid_label)\n",
        "\n",
        "    L = opt.seq_len\n",
        "\n",
        "    # [num_seq, seq_len, max_word_len+2]\n",
        "    num_seq = train_input.size()[0] //  L\n",
        "    train_input = train_input[:num_seq* L, :]\n",
        "    train_input = train_input.view(-1,  L, opt.max_word_len+2)\n",
        "\n",
        "    num_seq = valid_input.size()[0] //  L\n",
        "    valid_input = valid_input[:num_seq* L, :]\n",
        "    valid_input = valid_input.view(-1,  L, opt.max_word_len+2)\n",
        "\n",
        "    num_epoch = opt.epochs\n",
        "    num_iter_train = train_input.size()[0] // opt.batch_size\n",
        "    \n",
        "    learning_rate = opt.init_lr\n",
        "    old_PPL = 100000\n",
        "    best_PPL = 100000\n",
        "\n",
        "    n_stuck = 0\n",
        "\n",
        "    # Log-SoftMax\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    \n",
        "    X = torch.zeros((opt.batch_size,L,opt.max_word_len+2)).long().cuda()\n",
        "\n",
        "    for epoch in range(num_epoch):\n",
        "        ################  Validation  ####################\n",
        "        net.eval()\n",
        "        loss_batch = []\n",
        "        PPL_batch  = []\n",
        "        num_iter_valid = valid_input.size()[0] // opt.batch_size\n",
        "\n",
        "\n",
        "        # TRANSFORMER :\n",
        "        # VALID  : S+L sequences\n",
        "        # LABELS : S+L labels of next words -> use the (-L,1) labels\n",
        "        \n",
        "        valid_generator  = batch_generator(valid_input, opt.batch_size)\n",
        "        vlabel_generator = batch_generator(valid_label, opt.batch_size*L)\n",
        "\n",
        "        for t in range(num_iter_valid):\n",
        "            batch_input = valid_generator.__next__()  # (N,L,W)\n",
        "            batch_label = vlabel_generator.__next__() # (N*L)\n",
        "\n",
        "            ####################################################################\n",
        "            y_input  = batch_input[:,:,:].cuda()\n",
        "            batch_label = torch.reshape(batch_label,(opt.batch_size,L)).cuda()\n",
        "            y_pred      = batch_label[:,:].cuda().reshape(-1)\n",
        "            \n",
        "            ####################################################################\n",
        "            valid_output = net(X,y_input)\n",
        "\n",
        "            ####################################################################\n",
        "\n",
        "            ####\n",
        "            X = y_input\n",
        "            ####\n",
        "\n",
        "            length = valid_output.size()[0]\n",
        "\n",
        "            # [num_sample-1, len(word_dict)] vs [num_sample-1]\n",
        "            valid_loss = criterion(valid_output, to_var(y_pred))\n",
        "\n",
        "            PPL = torch.exp(valid_loss.data)\n",
        "\n",
        "            loss_batch.append(float(valid_loss))\n",
        "            PPL_batch.append(float(PPL))\n",
        "\n",
        "        PPL = np.mean(PPL_batch)\n",
        "        print(\"[epoch {}] valid PPL={}\".format(epoch, PPL))\n",
        "        print(\"valid loss={}\".format(np.mean(loss_batch)))\n",
        "        print(\"PPL decrease={}\".format(float(old_PPL - PPL)))\n",
        "\n",
        "        # UPDATE RESULTS DICT\n",
        "        if results.get(model_name) == None:\n",
        "            results[model_name] = {\"validation\":{\"loss\":[],\"PPL\":[]},\"training\":{\"loss\":[],\"PPL\":[]}}\n",
        "        results[model_name][\"validation\"][\"loss\"].append(np.mean(loss_batch))\n",
        "        results[model_name][\"validation\"][\"PPL\"].append(PPL)\n",
        "\n",
        "        # Preserve the best model\n",
        "        if best_PPL > PPL:\n",
        "            best_PPL = PPL\n",
        "            torch.save(net.state_dict(), \"cache/\"+model_name+\".pt\")\n",
        "            torch.save(net, \"cache/\"+model_name+\"_net.pkl\")\n",
        "\n",
        "        # Adjust the learning rate\n",
        "        if float(old_PPL - PPL) <= 1.0 and n_stuck > 5:\n",
        "            learning_rate /= 10\n",
        "            print(\"halved lr:{}\".format(learning_rate))\n",
        "            n_stuck = 0\n",
        "        elif float(old_PPL - PPL) <= 1.0:\n",
        "            n_stuck += 1\n",
        "\n",
        "        old_PPL = PPL\n",
        "\n",
        "        ##################################################\n",
        "        #################### Training ####################\n",
        "        net.train()\n",
        "\n",
        "        X = torch.zeros((opt.batch_size,L,opt.max_word_len+2)).long().cuda()\n",
        "\n",
        "        optimizer  = optim.Adam(net.parameters(), \n",
        "                               lr = learning_rate)\n",
        "\n",
        "        # split the first dim\n",
        "        input_generator = batch_generator(train_input, opt.batch_size)\n",
        "        label_generator = batch_generator(train_label, opt.batch_size*L)\n",
        "\n",
        "        total_loss, total_PPL = 0, 0\n",
        "\n",
        "        for t in range(num_iter_train):\n",
        "\n",
        "            if t % 100 == 0:\n",
        "                print(f\"{t}/{num_iter_train}\")\n",
        "\n",
        "            batch_input = input_generator.__next__()\n",
        "            batch_label = label_generator.__next__()\n",
        "\n",
        "            ####################################################################\n",
        "\n",
        "            y_input  = batch_input[:,:,:].cuda()\n",
        "            batch_label = torch.reshape(batch_label,(opt.batch_size,L)).cuda()\n",
        "            y_pred      = batch_label[:,:].cuda().reshape(-1)\n",
        "\n",
        "            ####################################################################\n",
        "            output = net(X,y_input)\n",
        "            # [num_word, vocab_size]\n",
        "            ####################################################################\n",
        "\n",
        "\n",
        "            loss = criterion(output, to_var(y_pred))\n",
        "  \n",
        "            net.zero_grad()\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm(net.parameters(), 5, norm_type=2)\n",
        "            optimizer.step()\n",
        "\n",
        "            ####\n",
        "            X = y_input\n",
        "            ####\n",
        "\n",
        "            total_loss += loss.cpu().data\n",
        "            total_PPL  += np.exp(loss.cpu().data)\n",
        "          \n",
        "        total_loss /= num_iter_train\n",
        "        total_PPL  /= num_iter_train\n",
        "    \n",
        "        results[model_name][\"training\"][\"loss\"].append(total_loss)\n",
        "        results[model_name][\"training\"][\"PPL\"].append(total_PPL)\n",
        "\n",
        "        print(f\"Train loss : {total_loss}\")\n",
        "        print(f\"Train PPL : {total_PPL}\")\n",
        "\n",
        "    torch.save(net.state_dict(), \"cache/\"+model_name+\".pt\")\n",
        "    print(\"Training finished.\")"
      ],
      "metadata": {
        "id": "a8KsFCMDszsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYoei0BALO-v"
      },
      "source": [
        "## Evaluation Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test LSTM"
      ],
      "metadata": {
        "id": "jSWpF8QtYhKR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_LSTM(net, data, opt, model_name):\n",
        "    net.eval()\n",
        "\n",
        "    test_input = torch.from_numpy(data.test_input)\n",
        "    test_label = torch.from_numpy(data.test_label)\n",
        "\n",
        "    L = opt.seq_len\n",
        "    num_seq = test_input.size()[0] // opt.seq_len\n",
        "    test_input = test_input[:num_seq*opt.seq_len, :]\n",
        "    # [num_seq, seq_len, max_word_len+2]\n",
        "    test_input = test_input.view(-1, opt.seq_len, opt.max_word_len+2)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    loss_list = []\n",
        "    num_iter_test = test_input.size()[0] // opt.batch_size\n",
        "    test_generator = batch_generator(test_input, opt.batch_size)\n",
        "    label_generator = batch_generator(test_label, opt.batch_size*opt.seq_len)\n",
        "\n",
        "    hidden = (to_var(torch.zeros(2, opt.batch_size, opt.word_embed_dim)), \n",
        "              to_var(torch.zeros(2, opt.batch_size, opt.word_embed_dim)))\n",
        "    \n",
        "    add_loss = 0.0 \n",
        "    for t in range(num_iter_test):\n",
        "        batch_input = test_generator.__next__ ()\n",
        "        batch_label = label_generator.__next__()\n",
        "        \n",
        "        net.zero_grad()\n",
        "        hidden = [state.detach() for state in hidden]\n",
        "        \n",
        "        test_output, hidden = net(to_var(batch_input), hidden)\n",
        "\n",
        "        test_loss = criterion(test_output, to_var(batch_label)).data\n",
        "\n",
        "        loss_list.append(test_loss)\n",
        "        add_loss += test_loss\n",
        "\n",
        "    print(\"Test Loss={0:.4f}\".format(float(add_loss) / num_iter_test))\n",
        "    print(\"Test PPL={0:.4f}\".format(float(torch.exp(add_loss / num_iter_test))))"
      ],
      "metadata": {
        "id": "jD6GBU4_eaTv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test Transformer"
      ],
      "metadata": {
        "id": "UhSXwAohYkBt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_Transformer(net, data, opt, model_name):\n",
        "    net.eval()\n",
        " \n",
        "    test_input = torch.from_numpy(data.test_input)\n",
        "    test_label = torch.from_numpy(data.test_label)\n",
        "\n",
        "    L = opt.seq_len\n",
        "    num_seq = test_input.size()[0] // opt.seq_len\n",
        "    test_input = test_input[:num_seq*opt.seq_len, :]\n",
        "    # [num_seq, seq_len, max_word_len+2]\n",
        "    test_input = test_input.view(-1, opt.seq_len, opt.max_word_len+2)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    loss_list = []\n",
        "    num_iter_test = test_input.size()[0] // opt.batch_size\n",
        "    test_generator = batch_generator(test_input, opt.batch_size)\n",
        "    label_generator = batch_generator(test_label, opt.batch_size*opt.seq_len)\n",
        "    \n",
        "    X = torch.zeros((opt.batch_size,L,opt.max_word_len+2)).long().cuda()\n",
        "\n",
        "    add_loss = 0.0 \n",
        "    for t in range(num_iter_test):\n",
        "        batch_input = test_generator.__next__ ()\n",
        "        batch_label = label_generator.__next__()\n",
        "\n",
        "        ####################################################################\n",
        "\n",
        "        y_input  = batch_input[:,:,:].cuda()\n",
        "        batch_label = torch.reshape(batch_label,(opt.batch_size,L)).cuda()\n",
        "        y_pred      = batch_label[:,:].cuda().reshape(-1)\n",
        "        ####################################################################\n",
        "        \n",
        "        net.zero_grad()\n",
        "\n",
        "        test_output = net(X,y_input)\n",
        "\n",
        "        X = y_input\n",
        "\n",
        "        test_loss = criterion(test_output, to_var(y_pred)).data\n",
        "\n",
        "        loss_list.append(test_loss)\n",
        "        add_loss += test_loss\n",
        "\n",
        "    print(\"Test Loss={0:.4f}\".format(float(add_loss) / num_iter_test))\n",
        "    print(\"Test PPL={0:.4f}\".format(float(torch.exp(add_loss / num_iter_test))))\n"
      ],
      "metadata": {
        "id": "ptaKpkJ5Yd2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1F-d6x1IxKkW"
      },
      "source": [
        "# **MODELS**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **LSTM model**"
      ],
      "metadata": {
        "id": "Fxbjsv64vCQv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Highway(nn.Module):\n",
        "    \"\"\"Highway network\"\"\"\n",
        "    def __init__(self, input_size):\n",
        "        super(Highway, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, input_size, bias=True)\n",
        "        self.fc2 = nn.Linear(input_size, input_size, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        t = F.sigmoid(self.fc1(x))\n",
        "        return torch.mul(t, F.relu(self.fc2(x))) + torch.mul(1-t, x)"
      ],
      "metadata": {
        "id": "syFejSRVbZ6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VeaOLj7DxMO9"
      },
      "outputs": [],
      "source": [
        "class charLM(nn.Module):\n",
        "    \"\"\"CNN + highway network + LSTM\n",
        "    # Input: \n",
        "        4D tensor with shape [batch_size, in_channel, height, width]\n",
        "    # Output:\n",
        "        2D Tensor with shape [batch_size, vocab_size]\n",
        "    # Arguments:\n",
        "        char_emb_dim: the size of each character's embedding\n",
        "        word_emb_dim: the size of each word's embedding\n",
        "        vocab_size: num of unique words\n",
        "        num_char: num of characters\n",
        "        use_gpu: True or False\n",
        "    \"\"\"\n",
        "    def __init__(self, char_emb_dim, word_emb_dim,  \n",
        "                vocab_size, num_char, use_gpu):\n",
        "        super(charLM, self).__init__()\n",
        "        self.char_emb_dim = char_emb_dim\n",
        "        self.word_emb_dim = word_emb_dim\n",
        "        self.vocab_size = vocab_size\n",
        "\n",
        "        # char embedding layer\n",
        "        self.char_embed = nn.Embedding(num_char, char_emb_dim)\n",
        "\n",
        "        # convolutions of filters with different sizes\n",
        "        self.convolutions = []\n",
        "\n",
        "        # list of tuples: (the number of filter, width)\n",
        "        self.filter_num_width = [(25, 1), (50, 2), (75, 3), (100, 4), (125, 5), (150, 6)]\n",
        "        \n",
        "        for out_channel, filter_width in self.filter_num_width:\n",
        "            self.convolutions.append(\n",
        "                nn.Conv2d(\n",
        "                    1,           # in_channel\n",
        "                    out_channel, # out_channel\n",
        "                    kernel_size=(char_emb_dim, filter_width), # (height, width)\n",
        "                    bias=True\n",
        "                    )\n",
        "            )\n",
        "\n",
        "        self.highway_input_dim = sum([x for x, y in self.filter_num_width])\n",
        "\n",
        "        self.batch_norm = nn.BatchNorm1d(self.highway_input_dim, affine=False)\n",
        "\n",
        "        # highway net\n",
        "        self.highway1 = Highway(self.highway_input_dim)\n",
        "        self.highway2 = Highway(self.highway_input_dim)\n",
        "\n",
        "        # LSTM\n",
        "        self.lstm_num_layers = 2\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size=self.highway_input_dim, \n",
        "                            hidden_size=self.word_emb_dim, \n",
        "                            num_layers=self.lstm_num_layers,\n",
        "                            bias=True,\n",
        "                            dropout=0.5,\n",
        "                            batch_first=True)\n",
        "\n",
        "        # output layer\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "        self.linear = nn.Linear(self.word_emb_dim, self.vocab_size)\n",
        "\n",
        "        \n",
        "        if use_gpu is True:\n",
        "            for x in range(len(self.convolutions)):\n",
        "                self.convolutions[x] = self.convolutions[x].cuda()\n",
        "            self.highway1 = self.highway1.cuda()\n",
        "            self.highway2 = self.highway2.cuda()\n",
        "            self.lstm = self.lstm.cuda()\n",
        "            self.dropout = self.dropout.cuda()\n",
        "            self.char_embed = self.char_embed.cuda()\n",
        "            self.linear = self.linear.cuda()\n",
        "            self.batch_norm = self.batch_norm.cuda()\n",
        "\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        # Input: Variable of Tensor with shape [num_seq, seq_len, max_word_len+2]\n",
        "        # Return: Variable of Tensor with shape [num_words, len(word_dict)]\n",
        "        batch_size = x.size()[0]\n",
        "        lstm_seq_len = x.size()[1]\n",
        "\n",
        "        x = x.contiguous().view(-1, x.size()[2])\n",
        "        # [num_seq*seq_len, max_word_len+2]\n",
        "        \n",
        "        x = self.char_embed(x)\n",
        "        # [num_seq*seq_len, max_word_len+2, char_emb_dim]\n",
        "        \n",
        "        x = torch.transpose(x.view(x.size()[0], 1, x.size()[1], -1), 2, 3)\n",
        "        # [num_seq*seq_len, 1, max_word_len+2, char_emb_dim]\n",
        "        \n",
        "        x = self.conv_layers(x)\n",
        "        # [num_seq*seq_len, total_num_filters]\n",
        "\n",
        "        x = self.batch_norm(x)\n",
        "        # [num_seq*seq_len, total_num_filters]\n",
        "\n",
        "        x = self.highway1(x)\n",
        "        x = self.highway2(x)\n",
        "        # [num_seq*seq_len, total_num_filters]\n",
        "\n",
        "        x = x.contiguous().view(batch_size,lstm_seq_len, -1)\n",
        "        # [num_seq, seq_len, total_num_filters]\n",
        "        \n",
        "        x, hidden = self.lstm(x, hidden)\n",
        "        # [seq_len, num_seq, hidden_size]\n",
        "        \n",
        "        x = self.dropout(x)\n",
        "        # [seq_len, num_seq, hidden_size]\n",
        "        \n",
        "        x = x.contiguous().view(batch_size*lstm_seq_len, -1)\n",
        "        # [num_seq*seq_len, hidden_size]\n",
        "\n",
        "        x = self.linear(x)\n",
        "        # [num_seq*seq_len, vocab_size]\n",
        "        return x, hidden\n",
        "\n",
        "\n",
        "    def conv_layers(self, x):\n",
        "        chosen_list = list()\n",
        "        for conv in self.convolutions:\n",
        "            feature_map = F.tanh(conv(x))\n",
        "            # (batch_size, out_channel, 1, max_word_len-width+1)\n",
        "            chosen = torch.max(feature_map, 3)[0]\n",
        "            # (batch_size, out_channel, 1)            \n",
        "            chosen = chosen.squeeze()\n",
        "            # (batch_size, out_channel)\n",
        "            chosen_list.append(chosen)\n",
        "        \n",
        "        # (batch_size, total_num_filers)\n",
        "        return torch.cat(chosen_list, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Transformer model**"
      ],
      "metadata": {
        "id": "R7RcKHLS2hXx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, dim_model, dropout_p, max_len):\n",
        "        super().__init__()\n",
        "        # Modified version from: https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n",
        "        # max_len determines how far the position can have an effect on a token (window)\n",
        "        \n",
        "        # Info\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "        \n",
        "        # Encoding - From formula\n",
        "        pos_encoding = torch.zeros(max_len, dim_model)\n",
        "        positions_list = torch.arange(0, max_len, dtype=torch.float).view(-1, 1) # 0, 1, 2, 3, 4, 5\n",
        "        division_term = torch.exp(torch.arange(0, dim_model, 2).float() * (-math.log(10000.0)) / dim_model) # 1000^(2i/dim_model)\n",
        "        \n",
        "        # PE(pos, 2i) = sin(pos/1000^(2i/dim_model))*\n",
        "        pos_encoding[:, 0::2] = torch.sin(positions_list * division_term)\n",
        "        \n",
        "        # PE(pos, 2i + 1) = cos(pos/1000^(2i/dim_model))\n",
        "        pos_encoding[:, 1::2] = torch.cos(positions_list * division_term)[:,:-1]\n",
        "        \n",
        "        # Saving buffer (same as parameter without gradients needed)\n",
        "        pos_encoding = pos_encoding.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer(\"pos_encoding\",pos_encoding)\n",
        "        \n",
        "    def forward(self, token_embedding: torch.tensor) -> torch.tensor:\n",
        "        # Residual connection + pos encoding\n",
        "        return self.dropout(token_embedding + self.pos_encoding[:token_embedding.size(0), :])\n"
      ],
      "metadata": {
        "id": "s1Xlmd5kiM7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(nn.Module):\n",
        "    \"\"\"\n",
        "    Model from \"A detailed guide to Pytorch's nn.Transformer() module.\", by\n",
        "    Daniel Melchor: https://medium.com/@danielmelchor/a-detailed-guide-to-pytorchs-nn-transformer-module-c80afbc9ffb1\n",
        "    \"\"\"\n",
        "    # Constructor\n",
        "    def __init__(\n",
        "        self,\n",
        "        dim_model,\n",
        "        num_heads,\n",
        "        num_encoder_layers,\n",
        "        num_decoder_layers,\n",
        "        dropout_p,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        # INFO\n",
        "        self.model_type = \"Transformer\"\n",
        "        self.dim_model = dim_model\n",
        "\n",
        "        # LAYERS\n",
        "        self.positional_encoder = PositionalEncoding(\n",
        "            dim_model=dim_model, dropout_p=dropout_p, max_len=5000\n",
        "        )\n",
        "        self.transformer = nn.Transformer(\n",
        "            d_model=dim_model,\n",
        "            nhead=num_heads,\n",
        "            num_encoder_layers=num_encoder_layers,\n",
        "            num_decoder_layers=num_decoder_layers,\n",
        "            dropout=dropout_p,\n",
        "            dim_feedforward=dim_model\n",
        "        )\n",
        "        \n",
        "    def forward(self, src, tgt, tgt_mask=None, src_pad_mask=None, tgt_pad_mask=None):\n",
        "        # Src size must be (batch_size, src sequence length)\n",
        "        # Tgt size must be (batch_size, tgt sequence length)\n",
        "\n",
        "        # Embedding + positional encoding - Out size = (batch_size, sequence length, dim_model)\n",
        "        src = self.positional_encoder(src)\n",
        "        tgt = self.positional_encoder(tgt)\n",
        "        \n",
        "        # We could use the parameter batch_first=True, but our KDL version doesn't support it yet, so we permute\n",
        "        # to obtain size (sequence length, batch_size, dim_model),\n",
        "        src = src.permute(1,0,2)\n",
        "        tgt = tgt.permute(1,0,2)\n",
        "\n",
        "        # Transformer blocks - Out size = (sequence length, batch_size, num_tokens)\n",
        "        transformer_out = self.transformer(src, tgt, tgt_mask=tgt_mask, src_key_padding_mask=src_pad_mask, tgt_key_padding_mask=tgt_pad_mask)\n",
        "        \n",
        "        return transformer_out\n",
        "      \n",
        "    def get_tgt_mask(self, size) -> torch.tensor:\n",
        "        # Generates a squeare matrix where the each row allows one word more to be seen\n",
        "        mask = torch.tril(torch.ones(size, size) == 1) # Lower triangular matrix\n",
        "        mask = mask.float()\n",
        "        mask = mask.masked_fill(mask == 0, float('-inf')) # Convert zeros to -inf\n",
        "        mask = mask.masked_fill(mask == 1, float(0.0)) # Convert ones to 0\n",
        "        \n",
        "        # EX for size=5:\n",
        "        # [[0., -inf, -inf, -inf, -inf],\n",
        "        #  [0.,   0., -inf, -inf, -inf],\n",
        "        #  [0.,   0.,   0., -inf, -inf],\n",
        "        #  [0.,   0.,   0.,   0., -inf],\n",
        "        #  [0.,   0.,   0.,   0.,   0.]]\n",
        "        \n",
        "        return mask\n",
        "    \n",
        "    def create_pad_mask(self, matrix: torch.tensor, pad_token: int) -> torch.tensor:\n",
        "        # If matrix = [1,2,3,0,0,0] where pad_token=0, the result mask is\n",
        "        # [False, False, False, True, True, True]\n",
        "        return (matrix == pad_token)\n"
      ],
      "metadata": {
        "id": "Wh7wARJn2jMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CONV + TRANSFORMER MODEL"
      ],
      "metadata": {
        "id": "oP5jgmCpMuiG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xUyeeXeC-e42"
      },
      "outputs": [],
      "source": [
        "class charTransformer(nn.Module):\n",
        "    \"\"\"CNN + highway network + LSTM\n",
        "    # Input: \n",
        "        4D tensor with shape [batch_size, in_channel, height, width]\n",
        "    # Output:\n",
        "        2D Tensor with shape [batch_size, vocab_size]\n",
        "    # Arguments:\n",
        "        char_emb_dim: the size of each character's embedding\n",
        "        word_emb_dim: the size of each word's embedding\n",
        "        vocab_size: num of unique words\n",
        "        num_char: num of characters\n",
        "        use_gpu: True or False\n",
        "    \"\"\"\n",
        "    def __init__(self, char_emb_dim, word_emb_dim,  \n",
        "                vocab_size, num_char, use_gpu):\n",
        "        super(charTransformer, self).__init__()\n",
        "        self.char_emb_dim = char_emb_dim\n",
        "        self.word_emb_dim = word_emb_dim\n",
        "        self.vocab_size = vocab_size\n",
        "\n",
        "        # char embedding layer\n",
        "        self.char_embed = nn.Embedding(num_char, char_emb_dim)\n",
        "\n",
        "        # convolutions of filters with different sizes\n",
        "        self.convolutions = []\n",
        "\n",
        "        # list of tuples: (the number of filter, width)\n",
        "        self.filter_num_width = [(25, 1), (50, 2), (75, 3), (100, 4), (125, 5), (150, 6)]\n",
        "        \n",
        "        for out_channel, filter_width in self.filter_num_width:\n",
        "            self.convolutions.append(\n",
        "                nn.Conv2d(\n",
        "                    1,           # in_channel\n",
        "                    out_channel, # out_channel\n",
        "                    kernel_size=(char_emb_dim, filter_width), # (height, width)\n",
        "                    bias=True\n",
        "                    )\n",
        "            )\n",
        "\n",
        "        self.highway_input_dim = sum([x for x, y in self.filter_num_width])\n",
        "\n",
        "        self.batch_norm = nn.BatchNorm1d(self.highway_input_dim, affine=False)\n",
        "\n",
        "        # highway net\n",
        "        self.highway1 = Highway(self.highway_input_dim)\n",
        "        self.highway2 = Highway(self.highway_input_dim)\n",
        "\n",
        "        ########################################################################\n",
        "        ################### MODIFICATION HERE ##################################\n",
        "\n",
        "        # Transformer\n",
        "        self.transformer = Transformer(\n",
        "          dim_model=self.word_emb_dim, num_heads=3, num_encoder_layers=1, num_decoder_layers=1, dropout_p=0.5\n",
        "        )\n",
        "\n",
        "        # output layer\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "        self.linear = nn.Linear(self.word_emb_dim, self.vocab_size)\n",
        "\n",
        "        ########################################################################\n",
        "        ########################################################################\n",
        "\n",
        "        \n",
        "        if use_gpu is True:\n",
        "            for x in range(len(self.convolutions)):\n",
        "                self.convolutions[x] = self.convolutions[x].cuda()\n",
        "            self.highway1 = self.highway1.cuda()\n",
        "            self.highway2 = self.highway2.cuda()\n",
        "            self.transformer = self.transformer.cuda()\n",
        "            self.dropout = self.dropout.cuda()\n",
        "            self.char_embed = self.char_embed.cuda()\n",
        "            self.linear = self.linear.cuda()\n",
        "            self.batch_norm = self.batch_norm.cuda()\n",
        "            self.use_gpu = True\n",
        "        else:\n",
        "          self.use_gpu = False\n",
        "\n",
        "\n",
        "    def forward(self, x, y_input):\n",
        "\n",
        "\n",
        "        ########################################################################\n",
        "        ######### SHIFT Y_input BATCH RIGHT ####################################\n",
        "\n",
        "        '''\n",
        "        start_words = torch.full((y_input.shape[0], 1, y_input.shape[2]), num_char+1).cuda()\n",
        "        y_input     = torch.cat((start_words,y_input),dim=1)\n",
        "        y_input     = y_input[:,:-1]\n",
        "        '''\n",
        "\n",
        "        # Input: Variable of Tensor with shape [num_seq, seq_len, max_word_len+2]\n",
        "        # Return: Variable of Tensor with shape [num_words, len(word_dict)]\n",
        "        batch_size = x.size()[0]\n",
        "        seq_len = x.size()[1]\n",
        "        L = y_input.shape[1]\n",
        "        ########################################################################\n",
        "        ########################################################################\n",
        "        x = x.contiguous().view(-1, x.size()[2])\n",
        "        y_input = y_input.contiguous().view(-1, y_input.size()[2])       \n",
        "        # [num_seq*seq_len, max_word_len+2]\n",
        "        \n",
        "        x = self.char_embed(x)\n",
        "        y_input = self.char_embed(y_input)\n",
        "        # [num_seq*seq_len, max_word_len+2, char_emb_dim]\n",
        "        \n",
        "        x = torch.transpose(x.view(x.size()[0], 1, x.size()[1], -1), 2, 3)\n",
        "        y_input = torch.transpose(y_input.view(y_input.size()[0], 1, y_input.size()[1], -1), 2, 3)\n",
        "        # [num_seq*seq_len, 1, max_word_len+2, char_emb_dim]\n",
        "        \n",
        "        x = self.conv_layers(x)\n",
        "        y_input = self.conv_layers(y_input)\n",
        "        # [num_seq*seq_len, total_num_filters]\n",
        "\n",
        "        x = self.batch_norm(x)\n",
        "        y_input = self.batch_norm(y_input)\n",
        "        # [num_seq*seq_len, total_num_filters]\n",
        "\n",
        "        x = self.highway1(x)\n",
        "        x = self.highway2(x)\n",
        "        y_input = self.highway1(y_input)\n",
        "        y_input = self.highway2(y_input)\n",
        "        # [num_seq*seq_len, total_num_filters]\n",
        "\n",
        "        x = x.contiguous().view(batch_size,seq_len, -1)\n",
        "        y_input = y_input.contiguous().view(batch_size,L, -1)\n",
        "        # [num_seq, seq_len, total_num_filters]\n",
        "        \n",
        "        ########################################################################\n",
        "        ################### MODIFICATION HERE ##################################\n",
        "        tgt_mask = self.transformer.get_tgt_mask(y_input.shape[1])\n",
        "        out        = self.transformer(x, y_input, tgt_mask.cuda()) if self.use_gpu else self.transformer(x, y_input, tgt_mask)\n",
        "        out = out.permute(1,0,2)\n",
        "        # [num_seq, seq_len, total_num_filters]\n",
        "\n",
        "        ########################################################################\n",
        "        ########################################################################\n",
        "        \n",
        "        out = self.dropout(out)\n",
        "        # [seq_len, num_seq, total_num_filters]\n",
        "        \n",
        "        out = out.contiguous().view(batch_size*L, -1)\n",
        "        # [num_seq*seq_len, total_num_filters]\n",
        "\n",
        "        out = self.linear(out)\n",
        "        # [num_seq*seq_len, vocab_size]\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "    def conv_layers(self, x):\n",
        "        chosen_list = list()\n",
        "        for conv in self.convolutions:\n",
        "            feature_map = F.tanh(conv(x))\n",
        "            # (batch_size, out_channel, 1, max_word_len-width+1)\n",
        "            chosen = torch.max(feature_map, 3)[0]\n",
        "            # (batch_size, out_channel, 1)            \n",
        "            chosen = chosen.squeeze()\n",
        "            # (batch_size, out_channel)\n",
        "            chosen_list.append(chosen)\n",
        "        \n",
        "        # (batch_size, total_num_filers)\n",
        "        return torch.cat(chosen_list, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2PTzcw3xYwl"
      },
      "source": [
        "# **MAIN**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameters"
      ],
      "metadata": {
        "id": "0mwHhn0zym7N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "architecture = \"LSTM\"    # LSTM | transformer\n",
        "corpus       = \"Brown\"   # Brown | ...\n",
        "\n",
        "#######################\n",
        "\n",
        "word_embed_dim     = 525\n",
        "char_embedding_dim = 32\n",
        "USE_GPU            = True\n",
        "seq_len       = 64\n",
        "batch_size    = 16\n",
        "\n",
        "init_lr = 1e-4\n",
        "epochs = 20"
      ],
      "metadata": {
        "id": "3Veco3CPyL_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "DsERDNpIyo5T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* La phrase source doit comporter de l'info du batch precedent, comme entrainement LSTM \n",
        "\n",
        "* Deux choix : concat tout les inputs precedent ou juste prendre le precedent\n",
        "\n",
        "* Maintenant, comme pour LSTM, on predit les lettres suivantes "
      ],
      "metadata": {
        "id": "jEFyGN-m-pMK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1) data prep"
      ],
      "metadata": {
        "id": "j6fZe4Bdtn6Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if corpus == \"Brown\":\n",
        "    init_brown()\n",
        "\n",
        "if architecture == \"LSTM\":\n",
        "    model_archi = charLM\n",
        "else:\n",
        "    model_archi = charTransformer\n",
        "\n",
        "model_name = architecture+\"_\"+corpus+\"_model\"\n",
        "\n",
        "if not os.path.exists(path+\"results.pt\"):\n",
        "    results = {}\n",
        "    results[model_name] = {\"validation\":{\"loss\":[],\"PPL\":[]},\"training\":{\"loss\":[],\"PPL\":[]}}\n",
        "else:\n",
        "    results = torch.load(path+\"results.pt\")\n",
        "\n",
        "if os.path.exists(path+\"cache/prep_\"+corpus+\".pt\") is False:\n",
        "      preprocess()\n",
        "\n",
        "objetcs = torch.load(path+\"cache/prep_\"+corpus+\".pt\")\n",
        "word_dict         = objetcs[\"word_dict\"]\n",
        "char_dict         = objetcs[\"char_dict\"]\n",
        "reverse_word_dict = objetcs[\"reverse_word_dict\"]\n",
        "max_word_len      = objetcs[\"max_word_len\"]\n",
        "num_words         = len(word_dict)\n",
        "\n",
        "print(\"word/char dictionary built. Start making inputs.\")\n",
        "\n",
        "if os.path.exists(path+\"cache/data_sets_\"+corpus+\".pt\") is False:\n",
        "    dataset_prep()\n",
        "\n",
        "data_sets = torch.load(path+\"cache/data_sets_\"+corpus+\".pt\")\n",
        "train_set = data_sets[\"tdata\"]\n",
        "valid_set = data_sets[\"vdata\"]\n",
        "test_set  = data_sets[\"test\"]\n",
        "train_label = data_sets[\"trlabel\"]\n",
        "valid_label = data_sets[\"vlabel\"]\n",
        "test_label = data_sets[\"tlabel\"]\n",
        "\n",
        "DataTuple = namedtuple(\"DataTuple\", \n",
        "            \"train_input train_label valid_input valid_label test_input test_label\")\n",
        "data = DataTuple(train_input=train_set,\n",
        "                  train_label=train_label,\n",
        "                  valid_input=valid_set,\n",
        "                  valid_label=valid_label,\n",
        "                  test_input=test_set,\n",
        "                  test_label=test_label)\n",
        "\n",
        "print(\"Loaded data sets. Start building network.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QszlK741QPs",
        "outputId": "63c5e0df-327d-4579-b57b-d416393ce9c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n",
            "word/char dictionary built. Start making inputs.\n",
            "Loaded data sets. Start building network.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2) net"
      ],
      "metadata": {
        "id": "KNFQojCatqZm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YgnKaIfSxYc7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5487aee0-2a14-4e12-c4c8-f3af9b7fde4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Network built. Start training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  \n"
          ]
        }
      ],
      "source": [
        "net = model_archi(char_embedding_dim, \n",
        "            word_embed_dim, \n",
        "            num_words,\n",
        "            len(char_dict),\n",
        "            use_gpu=USE_GPU)\n",
        "\n",
        "for param in net.parameters():\n",
        "    nn.init.uniform(param.data, -0.05, 0.05)\n",
        "\n",
        "Options = namedtuple(\"Options\", [\n",
        "        \"init_lr\", \"seq_len\",\n",
        "        \"max_word_len\", \"batch_size\", \"epochs\",\n",
        "        \"word_embed_dim\"])\n",
        "opt = Options(init_lr=init_lr,\n",
        "              seq_len=seq_len,\n",
        "              max_word_len=max_word_len,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              word_embed_dim=word_embed_dim)\n",
        "\n",
        "print(\"Network built. Start training.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3) train"
      ],
      "metadata": {
        "id": "rN3pY1gQt-Np"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if (\"transformer\" in model_name):\n",
        "    train_Transformer(net, data, opt, model_name)\n",
        "else:\n",
        "    train_LSTM(net, data, opt, model_name)\n",
        "torch.save(results,path+\"results.pt\")\n",
        "torch.save(net, path+\"cache/\"+model_name+\"_net.pkl\")\n",
        "print(\"saved net\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQ8lxXsFt_s8",
        "outputId": "d2d4362b-0b72-440a-fb88-109a26ba00f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1933: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1944: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch 0] valid PPL=50249.74536780974\n",
            "valid loss=10.824759398941445\n",
            "PPL decrease=49750.25463219026\n",
            "0/226\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:134: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100/226\n",
            "200/226\n",
            "Train loss : 7.695529460906982\n",
            "Train PPL : 6366.12939453125\n",
            "[epoch 1] valid PPL=883.6718053226978\n",
            "valid loss=6.746518080213429\n",
            "PPL decrease=49366.07356248704\n",
            "0/226\n",
            "100/226\n",
            "200/226\n",
            "Train loss : 6.793012619018555\n",
            "Train PPL : 934.9397583007812\n",
            "[epoch 2] valid PPL=785.6537278436981\n",
            "valid loss=6.6164319409733325\n",
            "PPL decrease=98.01807747899966\n",
            "0/226\n",
            "100/226\n",
            "200/226\n",
            "Train loss : 6.60603666305542\n",
            "Train PPL : 771.5374145507812\n",
            "[epoch 3] valid PPL=736.6774761908878\n",
            "valid loss=6.54267473558409\n",
            "PPL decrease=48.97625165281033\n",
            "0/226\n",
            "100/226\n",
            "200/226\n",
            "Train loss : 6.478686332702637\n",
            "Train PPL : 680.6614990234375\n",
            "[epoch 4] valid PPL=678.1615292709486\n",
            "valid loss=6.453744373490325\n",
            "PPL decrease=58.51594691993921\n",
            "0/226\n",
            "100/226\n",
            "200/226\n",
            "Train loss : 6.359755039215088\n",
            "Train PPL : 605.2531127929688\n",
            "[epoch 5] valid PPL=620.3346492801093\n",
            "valid loss=6.361631587543319\n",
            "PPL decrease=57.8268799908393\n",
            "0/226\n",
            "100/226\n",
            "200/226\n",
            "Train loss : 6.267028331756592\n",
            "Train PPL : 552.58349609375\n",
            "[epoch 6] valid PPL=577.6461045256758\n",
            "valid loss=6.288099137027706\n",
            "PPL decrease=42.68854475443345\n",
            "0/226\n",
            "100/226\n",
            "200/226\n",
            "Train loss : 6.19574499130249\n",
            "Train PPL : 515.0702514648438\n",
            "[epoch 7] valid PPL=549.5057294727427\n",
            "valid loss=6.234712334860743\n",
            "PPL decrease=28.14037505293311\n",
            "0/226\n",
            "100/226\n",
            "200/226\n",
            "Train loss : 6.136373519897461\n",
            "Train PPL : 485.6150817871094\n",
            "[epoch 8] valid PPL=526.5281896000415\n",
            "valid loss=6.1892216184497935\n",
            "PPL decrease=22.977539872701186\n",
            "0/226\n",
            "100/226\n",
            "200/226\n",
            "Train loss : 6.086564064025879\n",
            "Train PPL : 462.39910888671875\n",
            "[epoch 9] valid PPL=506.39752899439986\n",
            "valid loss=6.148327776816039\n",
            "PPL decrease=20.13066060564165\n",
            "0/226\n",
            "100/226\n",
            "200/226\n",
            "Train loss : 6.049370765686035\n",
            "Train PPL : 445.8936462402344\n",
            "[epoch 10] valid PPL=492.9719516450325\n",
            "valid loss=6.118809345549187\n",
            "PPL decrease=13.425577349367359\n",
            "0/226\n",
            "100/226\n",
            "200/226\n",
            "Train loss : 6.011223793029785\n",
            "Train PPL : 429.9762268066406\n",
            "[epoch 11] valid PPL=479.88640547220683\n",
            "valid loss=6.090034915282663\n",
            "PPL decrease=13.085546172825673\n",
            "0/226\n",
            "100/226\n",
            "200/226\n",
            "Train loss : 5.976617813110352\n",
            "Train PPL : 415.9668884277344\n",
            "[epoch 12] valid PPL=467.7222759955752\n",
            "valid loss=6.063768775062224\n",
            "PPL decrease=12.164129476631615\n",
            "0/226\n",
            "100/226\n",
            "200/226\n",
            "Train loss : 5.952829360961914\n",
            "Train PPL : 406.2088928222656\n",
            "[epoch 13] valid PPL=459.6606172544766\n",
            "valid loss=6.043858380444282\n",
            "PPL decrease=8.061658741098597\n",
            "0/226\n",
            "100/226\n",
            "200/226\n",
            "Train loss : 5.924909591674805\n",
            "Train PPL : 395.20257568359375\n",
            "[epoch 14] valid PPL=452.0546810183905\n",
            "valid loss=6.025544542126951\n",
            "PPL decrease=7.605936236086109\n",
            "0/226\n",
            "100/226\n",
            "200/226\n",
            "Train loss : 5.90321683883667\n",
            "Train PPL : 386.77215576171875\n",
            "[epoch 15] valid PPL=444.75190964420284\n",
            "valid loss=6.008672558100877\n",
            "PPL decrease=7.302771374187671\n",
            "0/226\n",
            "100/226\n",
            "200/226\n",
            "Train loss : 5.881782054901123\n",
            "Train PPL : 378.6561584472656\n",
            "[epoch 16] valid PPL=439.8308479511632\n",
            "valid loss=5.9953293758156025\n",
            "PPL decrease=4.921061693039633\n",
            "0/226\n",
            "100/226\n",
            "200/226\n",
            "Train loss : 5.86019229888916\n",
            "Train PPL : 370.49652099609375\n",
            "[epoch 17] valid PPL=435.01242956651\n",
            "valid loss=5.9839362718362725\n",
            "PPL decrease=4.818418384653228\n",
            "0/226\n",
            "100/226\n",
            "200/226\n",
            "Train loss : 5.842715740203857\n",
            "Train PPL : 364.5418395996094\n",
            "[epoch 18] valid PPL=430.0645575059199\n",
            "valid loss=5.971357560790746\n",
            "PPL decrease=4.9478720605901\n",
            "0/226\n",
            "100/226\n",
            "200/226\n",
            "Train loss : 5.820809364318848\n",
            "Train PPL : 356.5361022949219\n",
            "[epoch 19] valid PPL=426.37596873055514\n",
            "valid loss=5.961422865369679\n",
            "PPL decrease=3.6885887753647353\n",
            "0/226\n",
            "100/226\n",
            "200/226\n",
            "Train loss : 5.8041090965271\n",
            "Train PPL : 350.472900390625\n",
            "Training finished.\n",
            "saved net\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4) test"
      ],
      "metadata": {
        "id": "B-oJVofEu5UM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if (\"transformer\" in model_name):\n",
        "    test_Transformer(net, data, opt, model_name)\n",
        "else:\n",
        "    test_LSTM(net, data, opt, model_name)"
      ],
      "metadata": {
        "id": "82W-QCFd3ML5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bc98ffa-28b2-4696-9f74-c83273b43f05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1933: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1944: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss=6.8604\n",
            "Test PPL=953.7209\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Evaluation**"
      ],
      "metadata": {
        "id": "ij2HPzsEzE4u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Graphs"
      ],
      "metadata": {
        "id": "Fn1cFslEz2Q4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_loss, val_ppl = results[model_name][\"validation\"][\"loss\"], results[model_name][\"validation\"][\"PPL\"]\n",
        "N = len(val_loss)"
      ],
      "metadata": {
        "id": "47kIBjghz8QN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "\n",
        "plt.plot(range(N),val_loss,label=\"Validation\",color=\"green\")\n",
        "plt.plot(range(N),val_loss,label=\"Training\",color=\"blue\")\n",
        "\n",
        "plt.xlabel(\"Epoch\",fontsize=18)\n",
        "plt.ylabel(\"Loss\",fontsize=18)\n",
        "plt.title(\"Character-aware \"+architecture+\" model on the \"+corpus+\" Corpus\",fontsize=18)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vjkfQc9C0GDR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 634
        },
        "outputId": "c95df1ad-70bc-4962-bf18-c37bffe0df48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "j6fZe4Bdtn6Q",
        "KNFQojCatqZm"
      ],
      "name": "NLP-PROJECT_run_LSTM.ipynb",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}