{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1e_jsiIyvPON"
      },
      "source": [
        "# **IMPORTS & UTILS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7YcPJfCVvAUn"
      },
      "outputs": [],
      "source": [
        "import nltk, math, os, torch\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive \n",
        "from collections import namedtuple\n",
        "from nltk.corpus import brown\n",
        "import numpy as np\n",
        "\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "path = \"/content/drive/MyDrive/NLP_PROJECT/\"\n",
        "\n",
        "if not os.path.exists(path):\n",
        "  os.mkdir(path)\n",
        "\n",
        "if not os.path.exists(path+\"/cache/\"):\n",
        "  os.mkdir(path+\"/cache/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "677x_gECuDGR",
        "outputId": "511adb18-7cf4-4e1a-ec2b-8f428080f8bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AShS4PYrvTII"
      },
      "source": [
        "## **Corpus Initializations**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBEMxhwVvLzv"
      },
      "outputs": [],
      "source": [
        "def init_brown():\n",
        "  nltk.download('brown')\n",
        "  words = brown.words(categories=(brown.categories()))\n",
        "  N     = len(words)\n",
        "\n",
        "  words_test  = words[0:math.ceil(N*0.7)]\n",
        "  words_train = words[math.ceil(N*0.7):math.ceil(N*0.9)]\n",
        "  words_val   = words[math.ceil(N*0.9):]\n",
        "\n",
        "  f=open(path+'test.txt','w')\n",
        "  for w in words_test:\n",
        "      f.write(w+\" \")\n",
        "  f.close()\n",
        "\n",
        "  f=open(path+'train.txt','w')\n",
        "  for w in words_train:\n",
        "      f.write(w+\" \")\n",
        "  f.close()\n",
        "\n",
        "  f=open(path+'valid.txt','w')\n",
        "  for w in words_val:\n",
        "      f.write(w+\" \")\n",
        "  f.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mnx3CKcGL4fz"
      },
      "source": [
        "## Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cUCyI1p8vseh"
      },
      "outputs": [],
      "source": [
        "def batch_generator(x, batch_size):\n",
        "    # x: [num_words, in_channel, height, width]\n",
        "    # partitions x into batches\n",
        "    num_step = x.size()[0] // batch_size\n",
        "    for t in range(num_step):\n",
        "        yield x[t*batch_size:(t+1)*batch_size]\n",
        "\n",
        "def text2vec(words, char_dict, max_word_len):\n",
        "    \"\"\" Return list of list of int \"\"\"\n",
        "    word_vec = []\n",
        "    for word in words:\n",
        "        vec = [char_dict[ch] for ch in word] \n",
        "        if len(vec) < max_word_len:\n",
        "            vec += [char_dict[\"PAD\"] for _ in range(max_word_len - len(vec))]\n",
        "        vec = [char_dict[\"BOW\"]] + vec + [char_dict[\"EOW\"]]\n",
        "        word_vec.append(vec)\n",
        "    return word_vec\n",
        "\n",
        "def seq2vec(input_words, char_embedding, char_embedding_dim, char_table):\n",
        "    \"\"\" convert the input strings into character embeddings \"\"\"\n",
        "    # input_words == list of string\n",
        "    # char_embedding == torch.nn.Embedding\n",
        "    # char_embedding_dim == int\n",
        "    # char_table == list of unique chars\n",
        "    # Returns: tensor of shape [len(input_words), char_embedding_dim, max_word_len+2]\n",
        "    max_word_len = max([len(word) for word in input_words])\n",
        "    print(\"max_word_len={}\".format(max_word_len))\n",
        "    tensor_list = []\n",
        "    \n",
        "    start_column = torch.ones(char_embedding_dim, 1)\n",
        "    end_column = torch.ones(char_embedding_dim, 1)\n",
        "\n",
        "    for word in input_words:\n",
        "        # convert string to word embedding\n",
        "        word_encoding = char_embedding_lookup(word, char_embedding, char_table)\n",
        "        # add start and end columns\n",
        "        word_encoding = torch.cat([start_column, word_encoding, end_column], 1)\n",
        "        # zero-pad right columns\n",
        "        word_encoding = F.pad(word_encoding, (0, max_word_len-word_encoding.size()[1]+2)).data\n",
        "        # create dimension\n",
        "        word_encoding = word_encoding.unsqueeze(0)\n",
        "\n",
        "        tensor_list.append(word_encoding)\n",
        "\n",
        "    return torch.cat(tensor_list, 0)\n",
        "\n",
        "def read_data(file_name):\n",
        "    # Return: list of strings\n",
        "    with open(file_name, 'r') as f:\n",
        "        corpus = f.read().lower()\n",
        "    import re\n",
        "    corpus = re.sub(r\"<unk>\", \"unk\", corpus)\n",
        "    return corpus.split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ye-PRFepxqYW"
      },
      "outputs": [],
      "source": [
        "def get_char_dict(vocabulary):\n",
        "    # vocabulary == dict of (word, int)\n",
        "    # Return: dict of (char, int), starting from 1\n",
        "    char_dict = dict()\n",
        "    count = 1\n",
        "    for word in vocabulary:\n",
        "        for ch in word:\n",
        "            if ch not in char_dict:\n",
        "                char_dict[ch] = count\n",
        "                count += 1\n",
        "    return char_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OnI9nY7kxnD6"
      },
      "outputs": [],
      "source": [
        "def create_word_char_dict(*file_name):\n",
        "    text = []\n",
        "    for file in file_name:\n",
        "        text += read_data(file)\n",
        "    word_dict = {word:ix for ix, word in enumerate(set(text))}\n",
        "    char_dict = get_char_dict(word_dict)\n",
        "    return word_dict, char_dict"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def to_var(x):\n",
        "    if torch.cuda.is_available():\n",
        "        x = x.cuda()\n",
        "    return Variable(x)"
      ],
      "metadata": {
        "id": "w4LoimA2vRcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_char = 0\n",
        "def preprocess(): \n",
        "    global num_char\n",
        "    word_dict, char_dict = create_word_char_dict(path+\"valid.txt\", path+\"train.txt\", path+\"test.txt\")\n",
        "    num_words = len(word_dict)\n",
        "    num_char  = len(char_dict)\n",
        "    char_dict[\"BOW\"] = num_char+1\n",
        "    char_dict[\"EOW\"] = num_char+2\n",
        "    char_dict[\"PAD\"] = 0\n",
        "    \n",
        "    #  dict of (int, string)\n",
        "    reverse_word_dict = {value:key for key, value in word_dict.items()}\n",
        "    max_word_len = max([len(word) for word in word_dict])\n",
        "\n",
        "    objects = {\n",
        "        \"word_dict\": word_dict,\n",
        "        \"char_dict\": char_dict,\n",
        "        \"reverse_word_dict\": reverse_word_dict,\n",
        "        \"max_word_len\": max_word_len\n",
        "    }\n",
        "    \n",
        "    torch.save(objects, path+\"cache/prep_\"+corpus+\".pt\")\n",
        "    print(\"Preprocess done.\")"
      ],
      "metadata": {
        "id": "X2JCvNvevNKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training loop"
      ],
      "metadata": {
        "id": "6aUeQz-64s7j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(net, data, opt, model_name):\n",
        "    global results\n",
        "\n",
        "    transformer_model = (\"transformer\" in model_name)\n",
        "\n",
        "    torch.manual_seed(1024)\n",
        "\n",
        "    train_input = torch.from_numpy(data.train_input)\n",
        "    train_label = torch.from_numpy(data.train_label)\n",
        "    valid_input = torch.from_numpy(data.valid_input)\n",
        "    valid_label = torch.from_numpy(data.valid_label)\n",
        "\n",
        "    ####################################################################\n",
        "    T = opt.lstm_seq_len\n",
        "    L = opt.lstm_seq_len\n",
        "    ####################################################################\n",
        "\n",
        "    # [num_seq, seq_len, max_word_len+2]\n",
        "    num_seq = train_input.size()[0] //  L\n",
        "    train_input = train_input[:num_seq* L, :]\n",
        "    train_input = train_input.view(-1,  L, opt.max_word_len+2)\n",
        "\n",
        "    num_seq = valid_input.size()[0] //  L\n",
        "    valid_input = valid_input[:num_seq* L, :]\n",
        "    valid_input = valid_input.view(-1,  L, opt.max_word_len+2)\n",
        "\n",
        "    num_epoch = opt.epochs\n",
        "    num_iter_per_epoch = train_input.size()[0] //  L\n",
        "    \n",
        "    learning_rate = opt.init_lr\n",
        "    old_PPL = 100000\n",
        "    best_PPL = 100000\n",
        "\n",
        "    n_stuck = 0\n",
        "\n",
        "    # Log-SoftMax\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    \n",
        "    # word_emb_dim == hidden_size / num of hidden units \n",
        "    hidden = (to_var(torch.zeros(2,  L, opt.word_embed_dim)), \n",
        "              to_var(torch.zeros(2,  L, opt.word_embed_dim)))\n",
        "    \n",
        "    X = torch.zeros((16,35,525)).long().cuda()\n",
        "\n",
        "    for epoch in range(num_epoch):\n",
        "        ################  Validation  ####################\n",
        "        net.eval()\n",
        "        loss_batch = []\n",
        "        PPL_batch  = []\n",
        "        iterations = valid_input.size()[0] //  L\n",
        "\n",
        "\n",
        "        # TRANSFORMER :\n",
        "        # VALID  : S+L sequences\n",
        "        # LABELS : S+L labels of next words -> use the (-L,1) labels\n",
        "        \n",
        "        valid_generator  = batch_generator(valid_input, opt.lstm_batch_size)\n",
        "        vlabel_generator = batch_generator(valid_label, opt.lstm_batch_size*L)\n",
        "\n",
        "        for t in range(iterations):\n",
        "            batch_input = valid_generator.__next__()  # (N,L,W)\n",
        "            batch_label = vlabel_generator.__next__() # (N*L)\n",
        "\n",
        "            ####################################################################\n",
        "            if transformer_model:\n",
        "              y_input  = batch_input[:,:,:].cuda()\n",
        "              batch_label = torch.reshape(batch_label,(opt.lstm_batch_size,L)).cuda()\n",
        "              y_pred      = batch_label[:,:].cuda().reshape(-1)\n",
        "\n",
        "            ####################################################################\n",
        "\n",
        "            hidden = [state.detach() for state in hidden]\n",
        "            \n",
        "            ####################################################################\n",
        "            if transformer_model:\n",
        "              valid_output = net(X,y_input)\n",
        "            else:\n",
        "              valid_output, hidden = net(to_var(batch_input), hidden)\n",
        "            ####################################################################\n",
        "\n",
        "            ####\n",
        "            X = y_input\n",
        "            ####\n",
        "\n",
        "            length = valid_output.size()[0]\n",
        "\n",
        "            # [num_sample-1, len(word_dict)] vs [num_sample-1]\n",
        "            if transformer_model:\n",
        "              valid_loss = criterion(valid_output, to_var(y_pred))\n",
        "            else: \n",
        "              valid_loss = criterion(valid_output, to_var(batch_label))\n",
        "\n",
        "            PPL = torch.exp(valid_loss.data)\n",
        "\n",
        "            loss_batch.append(float(valid_loss))\n",
        "            PPL_batch.append(float(PPL))\n",
        "\n",
        "        PPL = np.mean(PPL_batch)\n",
        "        print(\"[epoch {}] valid PPL={}\".format(epoch, PPL))\n",
        "        print(\"valid loss={}\".format(np.mean(loss_batch)))\n",
        "        print(\"PPL decrease={}\".format(float(old_PPL - PPL)))\n",
        "\n",
        "        # UPDATE RESULTS DICT\n",
        "        results[model_name][\"validation\"][\"loss\"].append(np.mean(loss_batch))\n",
        "        results[model_name][\"validation\"][\"PPL\"].append(PPL)\n",
        "\n",
        "        # Preserve the best model\n",
        "        if best_PPL > PPL:\n",
        "            best_PPL = PPL\n",
        "            torch.save(net.state_dict(), path+\"cache/\"+model_name+\".pt\")\n",
        "            torch.save(net, path+\"cache/\"+model_name+\"_net.pkl\")\n",
        "\n",
        "        # Adjust the learning rate\n",
        "        if float(old_PPL - PPL) <= 1.0 and n_stuck > 5:\n",
        "            learning_rate /= 10\n",
        "            print(\"halved lr:{}\".format(learning_rate))\n",
        "            n_stuck = 0\n",
        "        elif float(old_PPL - PPL) <= 1.0:\n",
        "          n_stuck += 1\n",
        "\n",
        "        old_PPL = PPL\n",
        "\n",
        "        ##################################################\n",
        "        #################### Training ####################\n",
        "        net.train()\n",
        "\n",
        "        X = torch.zeros((16,35,525)).long().cuda()\n",
        "\n",
        "        optimizer  = optim.Adam(net.parameters(), \n",
        "                               lr = learning_rate)\n",
        "\n",
        "        # split the first dim\n",
        "        input_generator = batch_generator(train_input, opt.lstm_batch_size)\n",
        "        label_generator = batch_generator(train_label, opt.lstm_batch_size*L)\n",
        "\n",
        "        total_loss, total_PPL = 0, 0\n",
        "\n",
        "        for t in range(num_iter_per_epoch):\n",
        "\n",
        "            if t % 100 == 0:\n",
        "              print(f\"{t}/{num_iter_per_epoch}\")\n",
        "\n",
        "            batch_input = input_generator.__next__()\n",
        "            batch_label = label_generator.__next__()\n",
        "\n",
        "            ####################################################################\n",
        "            if transformer_model:\n",
        "              y_input  = batch_input[:,:,:].cuda()\n",
        "              batch_label = torch.reshape(batch_label,(opt.lstm_batch_size,L)).cuda()\n",
        "              y_pred      = batch_label[:,:].cuda().reshape(-1)\n",
        "            ####################################################################\n",
        "\n",
        "            # detach hidden state of LSTM from last batch\n",
        "            hidden = [state.detach() for state in hidden]\n",
        "            \n",
        "            ####################################################################\n",
        "            if transformer_model:\n",
        "              output = net(X,y_input)\n",
        "            else:\n",
        "              output, hidden = net(to_var(batch_input), hidden)\n",
        "            # [num_word, vocab_size]\n",
        "            ####################################################################\n",
        "\n",
        "            if transformer_model:\n",
        "              loss = criterion(output, to_var(y_pred))\n",
        "            else: \n",
        "              loss = criterion(output, to_var(batch_label))\n",
        "\n",
        "            net.zero_grad()\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm(net.parameters(), 5, norm_type=2)\n",
        "            optimizer.step()\n",
        "\n",
        "            ####\n",
        "            X = y_input\n",
        "            ####\n",
        "\n",
        "            total_loss += loss.cpu().data\n",
        "            total_PPL  += np.exp(loss.cpu().data)\n",
        "          \n",
        "        total_loss /= num_iter_per_epoch \n",
        "        total_PPL  /= num_iter_per_epoch \n",
        "    \n",
        "        results[model_name][\"training\"][\"loss\"].append(total_loss)\n",
        "        results[model_name][\"training\"][\"PPL\"].append(total_PPL)\n",
        "\n",
        "        print(f\"Train loss : {total_loss}\")\n",
        "        print(f\"Train PPL : {total_PPL}\")\n",
        "\n",
        "    torch.save(net.state_dict(), path+\"cache/\"+model_name+\".pt\")\n",
        "    print(\"Training finished.\")"
      ],
      "metadata": {
        "id": "pViF2ID-4uty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYoei0BALO-v"
      },
      "source": [
        "## Evaluation Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KDwEvw6sLQii"
      },
      "outputs": [],
      "source": [
        "def test(net, data, opt, model_name):\n",
        "    net.eval()\n",
        "\n",
        "    transformer_model = (\"transformer\" in model_name)\n",
        " \n",
        "    test_input = torch.from_numpy(data.test_input)\n",
        "    test_label = torch.from_numpy(data.test_label)\n",
        "\n",
        "    num_seq = test_input.size()[0] // opt.lstm_seq_len\n",
        "    test_input = test_input[:num_seq*opt.lstm_seq_len, :]\n",
        "    # [num_seq, seq_len, max_word_len+2]\n",
        "    test_input = test_input.view(-1, opt.lstm_seq_len, opt.max_word_len+2)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    loss_list = []\n",
        "    num_hits = 0\n",
        "    total = 0\n",
        "    iterations = test_input.size()[0] // opt.lstm_batch_size\n",
        "    test_generator = batch_generator(test_input, opt.lstm_batch_size)\n",
        "    label_generator = batch_generator(test_label, opt.lstm_batch_size*opt.lstm_seq_len)\n",
        "\n",
        "    hidden = (to_var(torch.zeros(2, opt.lstm_batch_size, opt.word_embed_dim)), \n",
        "              to_var(torch.zeros(2, opt.lstm_batch_size, opt.word_embed_dim)))\n",
        "    \n",
        "    X = torch.zeros((16,35,525)).long().cuda()\n",
        "\n",
        "    add_loss = 0.0 \n",
        "    for t in range(iterations):\n",
        "        batch_input = test_generator.__next__ ()\n",
        "        batch_label = label_generator.__next__()\n",
        "\n",
        "        ####################################################################\n",
        "        if transformer_model:\n",
        "          y_input  = batch_input[:,:,:].cuda()\n",
        "          batch_label = torch.reshape(batch_label,(opt.lstm_batch_size,L)).cuda()\n",
        "          y_pred      = batch_label[:,:].cuda().reshape(-1)\n",
        "        ####################################################################\n",
        "        \n",
        "        net.zero_grad()\n",
        "        hidden = [state.detach() for state in hidden]\n",
        "\n",
        "        if transformer_model:\n",
        "          test_output = net(X,y_input)\n",
        "        else:\n",
        "          test_output, hidden = net(to_var(batch_input), hidden)\n",
        "\n",
        "        X = y_input\n",
        "\n",
        "        if transformer_model:\n",
        "          test_loss = criterion(test_output, to_var(y_pred)).data\n",
        "        else: \n",
        "          test_loss = criterion(test_output, to_var(batch_label)).data\n",
        "\n",
        "        loss_list.append(test_loss)\n",
        "        add_loss += test_loss\n",
        "\n",
        "    print(\"Test Loss={0:.4f}\".format(float(add_loss) / iterations))\n",
        "    print(\"Test PPL={0:.4f}\".format(float(np.exp(add_loss / iterations))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1F-d6x1IxKkW"
      },
      "source": [
        "# **MODELS**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **LSTM model**"
      ],
      "metadata": {
        "id": "Fxbjsv64vCQv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VeaOLj7DxMO9"
      },
      "outputs": [],
      "source": [
        "class Highway(nn.Module):\n",
        "    \"\"\"Highway network\"\"\"\n",
        "    def __init__(self, input_size):\n",
        "        super(Highway, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, input_size, bias=True)\n",
        "        self.fc2 = nn.Linear(input_size, input_size, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        t = F.sigmoid(self.fc1(x))\n",
        "        return torch.mul(t, F.relu(self.fc2(x))) + torch.mul(1-t, x)\n",
        "\n",
        "\n",
        "class charLM(nn.Module):\n",
        "    \"\"\"CNN + highway network + LSTM\n",
        "    # Input: \n",
        "        4D tensor with shape [batch_size, in_channel, height, width]\n",
        "    # Output:\n",
        "        2D Tensor with shape [batch_size, vocab_size]\n",
        "    # Arguments:\n",
        "        char_emb_dim: the size of each character's embedding\n",
        "        word_emb_dim: the size of each word's embedding\n",
        "        vocab_size: num of unique words\n",
        "        num_char: num of characters\n",
        "        use_gpu: True or False\n",
        "    \"\"\"\n",
        "    def __init__(self, char_emb_dim, word_emb_dim,  \n",
        "                vocab_size, num_char, use_gpu):\n",
        "        super(charLM, self).__init__()\n",
        "        self.char_emb_dim = char_emb_dim\n",
        "        self.word_emb_dim = word_emb_dim\n",
        "        self.vocab_size = vocab_size\n",
        "\n",
        "        # char embedding layer\n",
        "        self.char_embed = nn.Embedding(num_char, char_emb_dim)\n",
        "\n",
        "        # convolutions of filters with different sizes\n",
        "        self.convolutions = []\n",
        "\n",
        "        # list of tuples: (the number of filter, width)\n",
        "        self.filter_num_width = [(25, 1), (50, 2), (75, 3), (100, 4), (125, 5), (150, 6)]\n",
        "        \n",
        "        for out_channel, filter_width in self.filter_num_width:\n",
        "            self.convolutions.append(\n",
        "                nn.Conv2d(\n",
        "                    1,           # in_channel\n",
        "                    out_channel, # out_channel\n",
        "                    kernel_size=(char_emb_dim, filter_width), # (height, width)\n",
        "                    bias=True\n",
        "                    )\n",
        "            )\n",
        "\n",
        "        self.highway_input_dim = sum([x for x, y in self.filter_num_width])\n",
        "\n",
        "        self.batch_norm = nn.BatchNorm1d(self.highway_input_dim, affine=False)\n",
        "\n",
        "        # highway net\n",
        "        self.highway1 = Highway(self.highway_input_dim)\n",
        "        self.highway2 = Highway(self.highway_input_dim)\n",
        "\n",
        "        # LSTM\n",
        "        self.lstm_num_layers = 2\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size=self.highway_input_dim, \n",
        "                            hidden_size=self.word_emb_dim, \n",
        "                            num_layers=self.lstm_num_layers,\n",
        "                            bias=True,\n",
        "                            dropout=0.5,\n",
        "                            batch_first=True)\n",
        "\n",
        "        # output layer\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "        self.linear = nn.Linear(self.word_emb_dim, self.vocab_size)\n",
        "\n",
        "        \n",
        "        if use_gpu is True:\n",
        "            for x in range(len(self.convolutions)):\n",
        "                self.convolutions[x] = self.convolutions[x].cuda()\n",
        "            self.highway1 = self.highway1.cuda()\n",
        "            self.highway2 = self.highway2.cuda()\n",
        "            self.lstm = self.lstm.cuda()\n",
        "            self.dropout = self.dropout.cuda()\n",
        "            self.char_embed = self.char_embed.cuda()\n",
        "            self.linear = self.linear.cuda()\n",
        "            self.batch_norm = self.batch_norm.cuda()\n",
        "\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        # Input: Variable of Tensor with shape [num_seq, seq_len, max_word_len+2]\n",
        "        # Return: Variable of Tensor with shape [num_words, len(word_dict)]\n",
        "        lstm_batch_size = x.size()[0]\n",
        "        lstm_seq_len = x.size()[1]\n",
        "\n",
        "        x = x.contiguous().view(-1, x.size()[2])\n",
        "        # [num_seq*seq_len, max_word_len+2]\n",
        "        \n",
        "        x = self.char_embed(x)\n",
        "        # [num_seq*seq_len, max_word_len+2, char_emb_dim]\n",
        "        \n",
        "        x = torch.transpose(x.view(x.size()[0], 1, x.size()[1], -1), 2, 3)\n",
        "        # [num_seq*seq_len, 1, max_word_len+2, char_emb_dim]\n",
        "        \n",
        "        x = self.conv_layers(x)\n",
        "        # [num_seq*seq_len, total_num_filters]\n",
        "\n",
        "        x = self.batch_norm(x)\n",
        "        # [num_seq*seq_len, total_num_filters]\n",
        "\n",
        "        x = self.highway1(x)\n",
        "        x = self.highway2(x)\n",
        "        # [num_seq*seq_len, total_num_filters]\n",
        "\n",
        "        x = x.contiguous().view(lstm_batch_size,lstm_seq_len, -1)\n",
        "        # [num_seq, seq_len, total_num_filters]\n",
        "        \n",
        "        x, hidden = self.lstm(x, hidden)\n",
        "        # [seq_len, num_seq, hidden_size]\n",
        "        \n",
        "        x = self.dropout(x)\n",
        "        # [seq_len, num_seq, hidden_size]\n",
        "        \n",
        "        x = x.contiguous().view(lstm_batch_size*lstm_seq_len, -1)\n",
        "        # [num_seq*seq_len, hidden_size]\n",
        "\n",
        "        x = self.linear(x)\n",
        "        # [num_seq*seq_len, vocab_size]\n",
        "        return x, hidden\n",
        "\n",
        "\n",
        "    def conv_layers(self, x):\n",
        "        chosen_list = list()\n",
        "        for conv in self.convolutions:\n",
        "            feature_map = F.tanh(conv(x))\n",
        "            # (batch_size, out_channel, 1, max_word_len-width+1)\n",
        "            chosen = torch.max(feature_map, 3)[0]\n",
        "            # (batch_size, out_channel, 1)            \n",
        "            chosen = chosen.squeeze()\n",
        "            # (batch_size, out_channel)\n",
        "            chosen_list.append(chosen)\n",
        "        \n",
        "        # (batch_size, total_num_filers)\n",
        "        return torch.cat(chosen_list, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Transformer model**"
      ],
      "metadata": {
        "id": "R7RcKHLS2hXx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, dim_model, dropout_p, max_len):\n",
        "        super().__init__()\n",
        "        # Modified version from: https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n",
        "        # max_len determines how far the position can have an effect on a token (window)\n",
        "        \n",
        "        # Info\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "        \n",
        "        # Encoding - From formula\n",
        "        pos_encoding = torch.zeros(max_len, dim_model)\n",
        "        positions_list = torch.arange(0, max_len, dtype=torch.float).view(-1, 1) # 0, 1, 2, 3, 4, 5\n",
        "        division_term = torch.exp(torch.arange(0, dim_model, 2).float() * (-math.log(10000.0)) / dim_model) # 1000^(2i/dim_model)\n",
        "        \n",
        "        # PE(pos, 2i) = sin(pos/1000^(2i/dim_model))*\n",
        "        pos_encoding[:, 0::2] = torch.sin(positions_list * division_term)\n",
        "        \n",
        "        # PE(pos, 2i + 1) = cos(pos/1000^(2i/dim_model))\n",
        "        pos_encoding[:, 1::2] = torch.cos(positions_list * division_term)[:,:-1]\n",
        "        \n",
        "        # Saving buffer (same as parameter without gradients needed)\n",
        "        pos_encoding = pos_encoding.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer(\"pos_encoding\",pos_encoding)\n",
        "        \n",
        "    def forward(self, token_embedding: torch.tensor) -> torch.tensor:\n",
        "        # Residual connection + pos encoding\n",
        "        return self.dropout(token_embedding + self.pos_encoding[:token_embedding.size(0), :])\n"
      ],
      "metadata": {
        "id": "s1Xlmd5kiM7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(nn.Module):\n",
        "    \"\"\"\n",
        "    Model from \"A detailed guide to Pytorch's nn.Transformer() module.\", by\n",
        "    Daniel Melchor: https://medium.com/@danielmelchor/a-detailed-guide-to-pytorchs-nn-transformer-module-c80afbc9ffb1\n",
        "    \"\"\"\n",
        "    # Constructor\n",
        "    def __init__(\n",
        "        self,\n",
        "        dim_model,\n",
        "        num_heads,\n",
        "        num_encoder_layers,\n",
        "        num_decoder_layers,\n",
        "        dropout_p,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        # INFO\n",
        "        self.model_type = \"Transformer\"\n",
        "        self.dim_model = dim_model\n",
        "\n",
        "        # LAYERS\n",
        "        self.positional_encoder = PositionalEncoding(\n",
        "            dim_model=dim_model, dropout_p=dropout_p, max_len=5000\n",
        "        )\n",
        "        self.transformer = nn.Transformer(\n",
        "            d_model=dim_model,\n",
        "            nhead=num_heads,\n",
        "            num_encoder_layers=num_encoder_layers,\n",
        "            num_decoder_layers=num_decoder_layers,\n",
        "            dropout=dropout_p,\n",
        "            dim_feedforward=dim_model\n",
        "        )\n",
        "        \n",
        "    def forward(self, src, tgt, tgt_mask=None, src_pad_mask=None, tgt_pad_mask=None):\n",
        "        # Src size must be (batch_size, src sequence length)\n",
        "        # Tgt size must be (batch_size, tgt sequence length)\n",
        "\n",
        "        # Embedding + positional encoding - Out size = (batch_size, sequence length, dim_model)\n",
        "        src = self.positional_encoder(src)\n",
        "        tgt = self.positional_encoder(tgt)\n",
        "        \n",
        "        # We could use the parameter batch_first=True, but our KDL version doesn't support it yet, so we permute\n",
        "        # to obtain size (sequence length, batch_size, dim_model),\n",
        "        src = src.permute(1,0,2)\n",
        "        tgt = tgt.permute(1,0,2)\n",
        "\n",
        "        # Transformer blocks - Out size = (sequence length, batch_size, num_tokens)\n",
        "        transformer_out = self.transformer(src, tgt, tgt_mask=tgt_mask, src_key_padding_mask=src_pad_mask, tgt_key_padding_mask=tgt_pad_mask)\n",
        "        \n",
        "        return transformer_out\n",
        "      \n",
        "    def get_tgt_mask(self, size) -> torch.tensor:\n",
        "        # Generates a squeare matrix where the each row allows one word more to be seen\n",
        "        mask = torch.tril(torch.ones(size, size) == 1) # Lower triangular matrix\n",
        "        mask = mask.float()\n",
        "        mask = mask.masked_fill(mask == 0, float('-inf')) # Convert zeros to -inf\n",
        "        mask = mask.masked_fill(mask == 1, float(0.0)) # Convert ones to 0\n",
        "        \n",
        "        # EX for size=5:\n",
        "        # [[0., -inf, -inf, -inf, -inf],\n",
        "        #  [0.,   0., -inf, -inf, -inf],\n",
        "        #  [0.,   0.,   0., -inf, -inf],\n",
        "        #  [0.,   0.,   0.,   0., -inf],\n",
        "        #  [0.,   0.,   0.,   0.,   0.]]\n",
        "        \n",
        "        return mask\n",
        "    \n",
        "    def create_pad_mask(self, matrix: torch.tensor, pad_token: int) -> torch.tensor:\n",
        "        # If matrix = [1,2,3,0,0,0] where pad_token=0, the result mask is\n",
        "        # [False, False, False, True, True, True]\n",
        "        return (matrix == pad_token)\n"
      ],
      "metadata": {
        "id": "Wh7wARJn2jMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CONV + TRANSFORMER MODEL"
      ],
      "metadata": {
        "id": "6zhXvZlu-I8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xUyeeXeC-e42"
      },
      "outputs": [],
      "source": [
        "class charTransformer(nn.Module):\n",
        "    \"\"\"CNN + highway network + LSTM\n",
        "    # Input: \n",
        "        4D tensor with shape [batch_size, in_channel, height, width]\n",
        "    # Output:\n",
        "        2D Tensor with shape [batch_size, vocab_size]\n",
        "    # Arguments:\n",
        "        char_emb_dim: the size of each character's embedding\n",
        "        word_emb_dim: the size of each word's embedding\n",
        "        vocab_size: num of unique words\n",
        "        num_char: num of characters\n",
        "        use_gpu: True or False\n",
        "    \"\"\"\n",
        "    def __init__(self, char_emb_dim, word_emb_dim,  \n",
        "                vocab_size, num_char, use_gpu):\n",
        "        super(charTransformer, self).__init__()\n",
        "        self.char_emb_dim = char_emb_dim\n",
        "        self.word_emb_dim = word_emb_dim\n",
        "        self.vocab_size = vocab_size\n",
        "\n",
        "        # char embedding layer\n",
        "        self.char_embed = nn.Embedding(num_char, char_emb_dim)\n",
        "\n",
        "        # convolutions of filters with different sizes\n",
        "        self.convolutions = []\n",
        "\n",
        "        # list of tuples: (the number of filter, width)\n",
        "        self.filter_num_width = [(25, 1), (50, 2), (75, 3), (100, 4), (125, 5), (150, 6)]\n",
        "        \n",
        "        for out_channel, filter_width in self.filter_num_width:\n",
        "            self.convolutions.append(\n",
        "                nn.Conv2d(\n",
        "                    1,           # in_channel\n",
        "                    out_channel, # out_channel\n",
        "                    kernel_size=(char_emb_dim, filter_width), # (height, width)\n",
        "                    bias=True\n",
        "                    )\n",
        "            )\n",
        "\n",
        "        self.highway_input_dim = sum([x for x, y in self.filter_num_width])\n",
        "\n",
        "        self.batch_norm = nn.BatchNorm1d(self.highway_input_dim, affine=False)\n",
        "\n",
        "        # highway net\n",
        "        self.highway1 = Highway(self.highway_input_dim)\n",
        "        self.highway2 = Highway(self.highway_input_dim)\n",
        "\n",
        "        ########################################################################\n",
        "        ################### MODIFICATION HERE ##################################\n",
        "\n",
        "        # Transformer\n",
        "        self.transformer = Transformer(\n",
        "          dim_model=self.word_emb_dim, num_heads=3, num_encoder_layers=1, num_decoder_layers=1, dropout_p=0.5\n",
        "        )\n",
        "\n",
        "        # output layer\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "        self.linear = nn.Linear(self.word_emb_dim, self.vocab_size)\n",
        "\n",
        "        ########################################################################\n",
        "        ########################################################################\n",
        "\n",
        "        \n",
        "        if use_gpu is True:\n",
        "            for x in range(len(self.convolutions)):\n",
        "                self.convolutions[x] = self.convolutions[x].cuda()\n",
        "            self.highway1 = self.highway1.cuda()\n",
        "            self.highway2 = self.highway2.cuda()\n",
        "            self.transformer = self.transformer.cuda()\n",
        "            self.dropout = self.dropout.cuda()\n",
        "            self.char_embed = self.char_embed.cuda()\n",
        "            self.linear = self.linear.cuda()\n",
        "            self.batch_norm = self.batch_norm.cuda()\n",
        "            self.use_gpu = True\n",
        "        else:\n",
        "          self.use_gpu = False\n",
        "\n",
        "\n",
        "    def forward(self, x, y_input):\n",
        "\n",
        "\n",
        "        ########################################################################\n",
        "        ######### SHIFT Y_input BATCH RIGHT ####################################\n",
        "\n",
        "        '''\n",
        "        start_words = torch.full((y_input.shape[0], 1, y_input.shape[2]), num_char+1).cuda()\n",
        "        y_input     = torch.cat((start_words,y_input),dim=1)\n",
        "        y_input     = y_input[:,:-1]\n",
        "        '''\n",
        "\n",
        "        L = y_input.shape[1]\n",
        "        # Input: Variable of Tensor with shape [num_seq, seq_len, max_word_len+2]\n",
        "        # Return: Variable of Tensor with shape [num_words, len(word_dict)]\n",
        "        lstm_batch_size = x.size()[0]\n",
        "        lstm_seq_len = x.size()[1]\n",
        "        ########################################################################\n",
        "        ########################################################################\n",
        "\n",
        "        x = x.contiguous().view(-1, x.size()[2])\n",
        "        y_input = y_input.contiguous().view(-1, y_input.size()[2])\n",
        "        # [num_seq*seq_len, max_word_len+2]\n",
        "        \n",
        "        x = self.char_embed(x)\n",
        "        y_input = self.char_embed(y_input)\n",
        "        # [num_seq*seq_len, max_word_len+2, char_emb_dim]\n",
        "        \n",
        "        x = torch.transpose(x.view(x.size()[0], 1, x.size()[1], -1), 2, 3)\n",
        "        y_input = torch.transpose(y_input.view(y_input.size()[0], 1, y_input.size()[1], -1), 2, 3)\n",
        "        # [num_seq*seq_len, 1, max_word_len+2, char_emb_dim]\n",
        "        \n",
        "        x = self.conv_layers(x)\n",
        "        y_input = self.conv_layers(y_input)\n",
        "        # [num_seq*seq_len, total_num_filters]\n",
        "\n",
        "        x = self.batch_norm(x)\n",
        "        y_input = self.batch_norm(y_input)\n",
        "        # [num_seq*seq_len, total_num_filters]\n",
        "\n",
        "        x = self.highway1(x)\n",
        "        x = self.highway2(x)\n",
        "        y_input = self.highway1(y_input)\n",
        "        y_input = self.highway2(y_input)\n",
        "        # [num_seq*seq_len, total_num_filters]\n",
        "\n",
        "        x = x.contiguous().view(lstm_batch_size,lstm_seq_len, -1)\n",
        "        y_input = y_input.contiguous().view(lstm_batch_size,L, -1)\n",
        "        # [num_seq, seq_len, total_num_filters]\n",
        "        \n",
        "        ########################################################################\n",
        "        ################### MODIFICATION HERE ##################################\n",
        "        tgt_mask = self.transformer.get_tgt_mask(y_input.shape[1])\n",
        "        out        = self.transformer(x, y_input, tgt_mask.cuda()) if self.use_gpu else self.transformer(x, y_input, tgt_mask)\n",
        "        out = out.permute(1,0,2)\n",
        "        # [num_seq, seq_len, total_num_filters]\n",
        "\n",
        "        ########################################################################\n",
        "        ########################################################################\n",
        "        \n",
        "        out = self.dropout(out)\n",
        "        # [seq_len, num_seq, total_num_filters]\n",
        "        \n",
        "        out = out.contiguous().view(lstm_batch_size*L, -1)\n",
        "        # [num_seq*seq_len, total_num_filters]\n",
        "\n",
        "        out = self.linear(out)\n",
        "        # [num_seq*seq_len, vocab_size]\n",
        "\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "    def conv_layers(self, x):\n",
        "        chosen_list = list()\n",
        "        for conv in self.convolutions:\n",
        "            feature_map = F.tanh(conv(x))\n",
        "            # (batch_size, out_channel, 1, max_word_len-width+1)\n",
        "            chosen = torch.max(feature_map, 3)[0]\n",
        "            # (batch_size, out_channel, 1)            \n",
        "            chosen = chosen.squeeze()\n",
        "            # (batch_size, out_channel)\n",
        "            chosen_list.append(chosen)\n",
        "        \n",
        "        # (batch_size, total_num_filers)\n",
        "        return torch.cat(chosen_list, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2PTzcw3xYwl"
      },
      "source": [
        "# **MAIN**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameters"
      ],
      "metadata": {
        "id": "0mwHhn0zym7N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "architecture = \"transformer\"    # LSTM | transformer\n",
        "corpus       = \"Brown\"   # Brown | ...\n",
        "\n",
        "#######################\n",
        "\n",
        "word_embed_dim     = 525\n",
        "char_embedding_dim = 32\n",
        "USE_GPU            = True\n",
        "cnn_batch_size     = 700\n",
        "lstm_seq_len       = 35\n",
        "lstm_batch_size    = 16\n",
        "\n",
        "init_lr = 1e-4\n",
        "epochs = 20"
      ],
      "metadata": {
        "id": "3Veco3CPyL_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "DsERDNpIyo5T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* La phrase source doit comporter de l'info du batch precedent, comme entrainement LSTM \n",
        "\n",
        "* Deux choix : concat tout les inputs precedent ou juste prendre le precedent\n",
        "\n",
        "* Maintenant, comme pour LSTM, on predit les lettres suivantes "
      ],
      "metadata": {
        "id": "jEFyGN-m-pMK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YgnKaIfSxYc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "53be357c-bf60-44f6-82dd-fd012d298278"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "word/char dictionary built. Start making inputs.\n",
            "Loaded data sets. Start building network.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:78: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Network built. Start training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch 0] valid PPL=49703.518700132976\n",
            "valid loss=10.813826530537707\n",
            "PPL decrease=50296.481299867024\n",
            "0/189\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:171: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100/189\n",
            "Train loss : 10.343751907348633\n",
            "Train PPL : 33137.7265625\n",
            "[epoch 1] valid PPL=13502.964137300532\n",
            "valid loss=9.50881695240102\n",
            "PPL decrease=36200.55456283245\n",
            "0/189\n",
            "100/189\n",
            "Train loss : 8.688253402709961\n",
            "Train PPL : 6727.23828125\n",
            "[epoch 2] valid PPL=2475.3107299804688\n",
            "valid loss=7.801638968447421\n",
            "PPL decrease=11027.653407320064\n",
            "0/189\n",
            "100/189\n",
            "Train loss : 7.243224143981934\n",
            "Train PPL : 1458.2939453125\n",
            "[epoch 3] valid PPL=1122.8231785551031\n",
            "valid loss=6.994000252257002\n",
            "PPL decrease=1352.4875514253656\n",
            "0/189\n",
            "100/189\n",
            "Train loss : 6.897058010101318\n",
            "Train PPL : 1015.406005859375\n",
            "[epoch 4] valid PPL=1052.4318036018533\n",
            "valid loss=6.923489281471739\n",
            "PPL decrease=70.39137495324985\n",
            "0/189\n",
            "100/189\n",
            "Train loss : 6.834359645843506\n",
            "Train PPL : 956.0392456054688\n",
            "[epoch 5] valid PPL=1043.8106027156748\n",
            "valid loss=6.913748005603222\n",
            "PPL decrease=8.621200886178485\n",
            "0/189\n",
            "100/189\n",
            "Train loss : 6.7963762283325195\n",
            "Train PPL : 921.6793823242188\n",
            "[epoch 6] valid PPL=1028.8890127628408\n",
            "valid loss=6.898644812563632\n",
            "PPL decrease=14.921589952833983\n",
            "0/189\n",
            "100/189\n",
            "Train loss : 6.765686511993408\n",
            "Train PPL : 894.6444091796875\n",
            "[epoch 7] valid PPL=1011.6199197972074\n",
            "valid loss=6.880563832343893\n",
            "PPL decrease=17.269092965633376\n",
            "0/189\n",
            "100/189\n",
            "Train loss : 6.737457752227783\n",
            "Train PPL : 870.53125\n",
            "[epoch 8] valid PPL=992.5427252586852\n",
            "valid loss=6.861059467843238\n",
            "PPL decrease=19.077194538522235\n",
            "0/189\n",
            "100/189\n",
            "Train loss : 6.710286617279053\n",
            "Train PPL : 846.9064331054688\n",
            "[epoch 9] valid PPL=965.3268309248255\n",
            "valid loss=6.833337372921883\n",
            "PPL decrease=27.21589433385975\n",
            "0/189\n",
            "100/189\n",
            "Train loss : 6.683071136474609\n",
            "Train PPL : 824.4276733398438\n",
            "[epoch 10] valid PPL=946.7560457270196\n",
            "valid loss=6.813144374401011\n",
            "PPL decrease=18.57078519780589\n",
            "0/189\n",
            "100/189\n",
            "Train loss : 6.654462814331055\n",
            "Train PPL : 801.0501098632812\n",
            "[epoch 11] valid PPL=917.8854457774061\n",
            "valid loss=6.780373370393794\n",
            "PPL decrease=28.870599949613506\n",
            "0/189\n",
            "100/189\n",
            "Train loss : 6.6240034103393555\n",
            "Train PPL : 777.37353515625\n",
            "[epoch 12] valid PPL=890.0680574457696\n",
            "valid loss=6.748055493577998\n",
            "PPL decrease=27.817388331636494\n",
            "0/189\n",
            "100/189\n",
            "Train loss : 6.597599506378174\n",
            "Train PPL : 756.8329467773438\n",
            "[epoch 13] valid PPL=862.886035026388\n",
            "valid loss=6.716056468638968\n",
            "PPL decrease=27.18202241938161\n",
            "0/189\n",
            "100/189\n",
            "Train loss : 6.570272922515869\n",
            "Train PPL : 736.5238037109375\n",
            "[epoch 14] valid PPL=837.6916763630319\n",
            "valid loss=6.68503723245986\n",
            "PPL decrease=25.19435866335607\n",
            "0/189\n",
            "100/189\n",
            "Train loss : 6.546632289886475\n",
            "Train PPL : 719.2992553710938\n",
            "[epoch 15] valid PPL=816.7703652889171\n",
            "valid loss=6.659369625943772\n",
            "PPL decrease=20.921311074114783\n",
            "0/189\n",
            "100/189\n",
            "Train loss : 6.523159980773926\n",
            "Train PPL : 702.86083984375\n",
            "[epoch 16] valid PPL=797.949098302963\n",
            "valid loss=6.633897933554142\n",
            "PPL decrease=18.82126698595414\n",
            "0/189\n",
            "100/189\n",
            "Train loss : 6.500100135803223\n",
            "Train PPL : 686.792724609375\n",
            "[epoch 17] valid PPL=780.0529395570146\n",
            "valid loss=6.610492726589771\n",
            "PPL decrease=17.896158745948355\n",
            "0/189\n",
            "100/189\n",
            "Train loss : 6.483276844024658\n",
            "Train PPL : 675.2036743164062\n",
            "[epoch 18] valid PPL=772.3818135362991\n",
            "valid loss=6.599513982204681\n",
            "PPL decrease=7.671126020715519\n",
            "0/189\n",
            "100/189\n",
            "Train loss : 6.46196174621582\n",
            "Train PPL : 661.3181762695312\n",
            "[epoch 19] valid PPL=749.8963720443401\n",
            "valid loss=6.569349907814188\n",
            "PPL decrease=22.485441491959023\n",
            "0/189\n",
            "100/189\n",
            "Train loss : 6.444880485534668\n",
            "Train PPL : 650.912109375\n",
            "Training finished.\n",
            "saved net\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-18023171ecae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"saved net\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: test() missing 1 required positional argument: 'model_name'"
          ]
        }
      ],
      "source": [
        "if corpus == \"Brown\":\n",
        "  init_brown()\n",
        "\n",
        "if architecture == \"LSTM\":\n",
        "  model_archi = charLM\n",
        "else:\n",
        "  model_archi = charTransformer\n",
        "\n",
        "model_name = architecture+\"_\"+corpus+\"_model\"\n",
        "\n",
        "if not os.path.exists(path+\"results.pt\"):\n",
        "  results = {}\n",
        "  results[model_name] = {\"validation\":{\"loss\":[],\"PPL\":[]},\"training\":{\"loss\":[],\"PPL\":[]}}\n",
        "else:\n",
        "  results = torch.load(path+\"results.pt\")\n",
        "\n",
        "if os.path.exists(path+\"cache/prep_\"+corpus+\".pt\") is False:\n",
        "    preprocess()\n",
        "\n",
        "objetcs = torch.load(path+\"cache/prep_\"+corpus+\".pt\")\n",
        "\n",
        "word_dict         = objetcs[\"word_dict\"]\n",
        "char_dict         = objetcs[\"char_dict\"]\n",
        "reverse_word_dict = objetcs[\"reverse_word_dict\"]\n",
        "max_word_len      = objetcs[\"max_word_len\"]\n",
        "num_words         = len(word_dict)\n",
        "\n",
        "print(\"word/char dictionary built. Start making inputs.\")\n",
        "\n",
        "#if os.path.exists(path+\"cache/data_sets_\"+corpus+\".pt\") is False:\n",
        "if True:\n",
        "    train_text = read_data(path+\"train.txt\")\n",
        "    valid_text = read_data(path+\"valid.txt\")\n",
        "    test_text  = read_data(path+\"test.txt\")\n",
        "\n",
        "    train_set = np.array(text2vec(train_text, char_dict, max_word_len))\n",
        "    valid_set = np.array(text2vec(valid_text, char_dict, max_word_len))\n",
        "    test_set  = np.array(text2vec(test_text,  char_dict, max_word_len))\n",
        "\n",
        "    # Labels are next-word index in word_dict with the same length as inputs\n",
        "    train_label = np.array([word_dict[w] for w in train_text[1:]] + [word_dict[train_text[-1]]])\n",
        "    valid_label = np.array([word_dict[w] for w in valid_text[1:]] + [word_dict[valid_text[-1]]])\n",
        "    test_label  = np.array([word_dict[w] for w in test_text[1:]] + [word_dict[test_text[-1]]])\n",
        "\n",
        "    category = {\"tdata\":train_set, \"vdata\":valid_set, \"test\": test_set, \n",
        "                \"trlabel\":train_label, \"vlabel\":valid_label, \"tlabel\":test_label}\n",
        "    torch.save(category, path+\"cache/data_sets_\"+corpus+\".pt\") \n",
        "else:\n",
        "    data_sets = torch.load(path+\"cache/data_sets_\"+corpus+\".pt\")\n",
        "    train_set = data_sets[\"tdata\"]\n",
        "    valid_set = data_sets[\"vdata\"]\n",
        "    test_set  = data_sets[\"test\"]\n",
        "    train_label = data_sets[\"trlabel\"]\n",
        "    valid_label = data_sets[\"vlabel\"]\n",
        "    test_label = data_sets[\"tlabel\"]\n",
        "\n",
        "\n",
        "DataTuple = namedtuple(\"DataTuple\", \n",
        "            \"train_input train_label valid_input valid_label test_input test_label\")\n",
        "data = DataTuple(train_input=train_set,\n",
        "                  train_label=train_label,\n",
        "                  valid_input=valid_set,\n",
        "                  valid_label=valid_label,\n",
        "                  test_input=test_set,\n",
        "                  test_label=test_label)\n",
        "\n",
        "print(\"Loaded data sets. Start building network.\")\n",
        "\n",
        "# cnn_batch_size == lstm_seq_len * lstm_batch_size\n",
        "\n",
        "net = model_archi(char_embedding_dim, \n",
        "            word_embed_dim, \n",
        "            num_words,\n",
        "            len(char_dict),\n",
        "            use_gpu=USE_GPU)\n",
        "\n",
        "for param in net.parameters():\n",
        "    nn.init.uniform(param.data, -0.05, 0.05)\n",
        "\n",
        "Options = namedtuple(\"Options\", [\n",
        "        \"cnn_batch_size\", \"init_lr\", \"lstm_seq_len\",\n",
        "        \"max_word_len\", \"lstm_batch_size\", \"epochs\",\n",
        "        \"word_embed_dim\"])\n",
        "opt = Options(cnn_batch_size=lstm_seq_len*lstm_batch_size,\n",
        "              init_lr=init_lr,\n",
        "              lstm_seq_len=lstm_seq_len,\n",
        "              max_word_len=max_word_len,\n",
        "              lstm_batch_size=lstm_batch_size,\n",
        "              epochs=epochs,\n",
        "              word_embed_dim=word_embed_dim)\n",
        "\n",
        "print(\"Network built. Start training.\")\n",
        "\n",
        "train(net, data, opt, model_name)\n",
        "torch.save(results,path+\"results.pt\")\n",
        "\n",
        "torch.save(net, path+\"cache/\"+model_name+\"_net.pkl\")\n",
        "print(\"saved net\")\n",
        "\n",
        "test(net, data, opt, model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Evaluation**"
      ],
      "metadata": {
        "id": "ij2HPzsEzE4u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load(path+\"cache/\"+model_name+\"_net.pkl\")\n",
        "results = torch.load(path+\"results.pt\")\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "qAZNqUsazTfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Graphs"
      ],
      "metadata": {
        "id": "Fn1cFslEz2Q4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_loss, val_ppl = results[model_name][\"validation\"][\"loss\"], results[model_name][\"validation\"][\"PPL\"]\n",
        "N = len(val_loss)"
      ],
      "metadata": {
        "id": "47kIBjghz8QN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "\n",
        "plt.plot(range(N),val_loss,label=\"Validation\",color=\"green\")\n",
        "plt.plot(range(N),val_loss,label=\"Training\",color=\"blue\")\n",
        "\n",
        "plt.xlabel(\"Epoch\",fontsize=18)\n",
        "plt.ylabel(\"Loss\",fontsize=18)\n",
        "plt.title(\"Character-aware \"+architecture+\" model on the \"+corpus+\" Corpus\",fontsize=18)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vjkfQc9C0GDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Qualitative Analysis"
      ],
      "metadata": {
        "id": "_6eI5To_2KkQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ethUlfkDLIvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Quantitative Analysis"
      ],
      "metadata": {
        "id": "9emwgxwc2NGl"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "1F-d6x1IxKkW",
        "_6eI5To_2KkQ",
        "9emwgxwc2NGl",
        "v_o9JA_p_FtY"
      ],
      "name": "NLP-PROJECT.ipynb",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}